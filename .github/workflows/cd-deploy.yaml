name: CD - Deploy Model

on:
  workflow_run:
    workflows: ["CI - Test Model"]
    types: [ completed ]
    branches: [ main ]

env:
  ECR_REPOSITORY: ml-model-california-housing
  AWS_REGION: ap-northeast-2

jobs:
  deploy:
    name: Build and Deploy Model
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      # ============================================================
      # ECR Repository ìƒì„± (ì¡´ìž¬í•˜ì§€ ì•Šì„ ê²½ìš°)
      # ============================================================
      - name: Create ECR Repository if not exists
        env:
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
        run: |
          echo "ðŸ” Checking if ECR repository exists..."
          
          if aws ecr describe-repositories --repository-names $ECR_REPOSITORY 2>/dev/null; then
            echo "âœ… ECR repository '$ECR_REPOSITORY' already exists"
          else
            echo "ðŸ“¦ Creating ECR repository '$ECR_REPOSITORY'..."
            aws ecr create-repository \
              --repository-name $ECR_REPOSITORY \
              --image-scanning-configuration scanOnPush=true \
              --image-tag-mutability MUTABLE \
              --encryption-configuration encryptionType=AES256
            
            echo "âœ… ECR repository created successfully"
          fi

      - name: Set image tag
        id: image-tag
        run: |
          SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)
          echo "tag=v$(date +%Y%m%d)-${SHORT_SHA}" >> $GITHUB_OUTPUT
          echo "timestamp=$(date +%Y%m%d-%H%M%S)" >> $GITHUB_OUTPUT

      - name: Check if Dockerfile exists
        id: check-dockerfile
        run: |
          if [ -f "Dockerfile" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "âœ… Dockerfile found in repository"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸  Dockerfile not found - will generate automatically"
          fi
      
      - name: Generate Dockerfile (if not exists)
        if: steps.check-dockerfile.outputs.exists == 'false'
        run: |
          echo "ðŸ“ Generating application files for California Housing model..."
          
          # Create api.py - ì‹œìž‘ ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´ ìµœì í™”
          cat > api.py << 'APIEOF'
          from fastapi import FastAPI, HTTPException
          from pydantic import BaseModel, Field
          from typing import List
          import numpy as np
          from sklearn.datasets import fetch_california_housing
          from sklearn.ensemble import RandomForestRegressor
          from sklearn.model_selection import train_test_split
          import logging
          import os
          import time
          
          logging.basicConfig(level=logging.INFO)
          logger = logging.getLogger(__name__)
          
          app = FastAPI(
              title="California Housing Model API",
              description="ML model for California Housing price prediction",
              version=os.getenv("MODEL_VERSION", "1.0.0")
          )
          
          class PredictionInput(BaseModel):
              features: List[float] = Field(..., min_items=8, max_items=8)
          
          class PredictionOutput(BaseModel):
              prediction: float
              model_version: str
          
          # Global model
          model = None
          model_loaded = False
          
          @app.on_event("startup")
          async def load_model():
              global model, model_loaded
              start_time = time.time()
              logger.info("ðŸš€ Starting model loading...")
              
              try:
                  data = fetch_california_housing()
                  X_train, _, y_train, _ = train_test_split(
                      data.data, data.target, test_size=0.2, random_state=42
                  )
                  # n_estimatorsë¥¼ ì¤„ì—¬ì„œ ì‹œìž‘ ì‹œê°„ ë‹¨ì¶•
                  model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
                  model.fit(X_train, y_train)
                  model_loaded = True
                  elapsed = time.time() - start_time
                  logger.info(f"âœ… Model loaded successfully in {elapsed:.2f}s")
              except Exception as e:
                  logger.error(f"âŒ Model loading failed: {e}")
                  raise
          
          @app.get("/health")
          async def health():
              """Health check endpoint - ëª¨ë¸ ë¡œë”© ìƒíƒœ ë°˜í™˜"""
              return {
                  "status": "healthy" if model_loaded else "loading",
                  "model_loaded": model_loaded
              }
          
          @app.get("/ready")
          async def ready():
              """Readiness check - ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆì„ ë•Œë§Œ 200 ë°˜í™˜"""
              if not model_loaded:
                  raise HTTPException(status_code=503, detail="Model not ready")
              return {"status": "ready"}
          
          @app.post("/predict", response_model=PredictionOutput)
          async def predict(input_data: PredictionInput):
              if model is None or not model_loaded:
                  raise HTTPException(status_code=503, detail="Model not loaded")
              features = np.array(input_data.features).reshape(1, -1)
              prediction = model.predict(features)[0]
              return PredictionOutput(
                  prediction=float(prediction),
                  model_version=os.getenv("MODEL_VERSION", "1.0.0")
              )
          APIEOF
          
          # Create Dockerfile
          cat > Dockerfile << 'DOCKEREOF'
          FROM python:3.9-slim
          WORKDIR /app
          RUN pip install --no-cache-dir fastapi uvicorn scikit-learn numpy pydantic
          COPY api.py .
          ENV MODEL_VERSION=1.0.0
          EXPOSE 8080
          # uvicorn ì‹œìž‘ ì‹œ íƒ€ìž„ì•„ì›ƒ ì„¤ì •
          CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8080", "--timeout-keep-alive", "120"]
          DOCKEREOF
          
          echo "âœ… Generated api.py and Dockerfile"

      - name: Build Docker image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          echo "ðŸ”¨ Building Docker image..."
          docker build --platform linux/amd64 \
            --build-arg MODEL_VERSION=$IMAGE_TAG \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:latest \
            .
          echo "âœ… Image built: $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"

      - name: Push image to ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
          echo "âœ… Image pushed: $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"

      - name: Check Kubernetes configuration
        id: check-k8s
        run: |
          if [ -n "${{ secrets.KUBECONFIG_DATA }}" ]; then
            echo "configured=true" >> $GITHUB_OUTPUT
            echo "âœ… Kubernetes configuration available"
          else
            echo "configured=false" >> $GITHUB_OUTPUT
            echo "âš ï¸  KUBECONFIG_DATA not configured - skipping K8s deployment"
          fi

      - name: Set up kubectl
        if: steps.check-k8s.outputs.configured == 'true'
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
      
      - name: Install aws-iam-authenticator
        if: steps.check-k8s.outputs.configured == 'true'
        run: |
          echo "ðŸ“¦ Installing aws-iam-authenticator..."
          curl -Lo aws-iam-authenticator https://github.com/kubernetes-sigs/aws-iam-authenticator/releases/download/v0.6.11/aws-iam-authenticator_0.6.11_linux_amd64
          chmod +x ./aws-iam-authenticator
          sudo mv ./aws-iam-authenticator /usr/local/bin/
          aws-iam-authenticator version
          echo "âœ… aws-iam-authenticator installed"

      - name: Configure kubectl
        if: steps.check-k8s.outputs.configured == 'true'
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG_DATA }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          echo "âœ… kubectl configured"

      - name: Deploy to KServe
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo "ðŸš€ Deploying to KServe..."
          
          # InferenceService YAML ìƒì„± - ì‹œìž‘ ì‹œê°„ì„ ê³ ë ¤í•œ probe ì„¤ì •
          cat > inferenceservice.yaml << EOF
          apiVersion: serving.kserve.io/v1beta1
          kind: InferenceService
          metadata:
            name: california-housing-predictor
            namespace: $NAMESPACE
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            predictor:
              minReplicas: 1
              maxReplicas: 3
              containers:
                - name: predictor
                  image: $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
                  ports:
                    - containerPort: 8080
                      protocol: TCP
                  env:
                    - name: MODEL_VERSION
                      value: "$IMAGE_TAG"
                  resources:
                    requests:
                      cpu: "200m"
                      memory: "512Mi"
                    limits:
                      cpu: "1000m"
                      memory: "1Gi"
                  # ðŸ”§ í•µì‹¬: ëª¨ë¸ ë¡œë”© ì‹œê°„ì„ ê³ ë ¤í•œ probe ì„¤ì •
                  readinessProbe:
                    httpGet:
                      path: /health
                      port: 8080
                    initialDelaySeconds: 60
                    periodSeconds: 10
                    timeoutSeconds: 10
                    failureThreshold: 6
                    successThreshold: 1
                  livenessProbe:
                    httpGet:
                      path: /health
                      port: 8080
                    initialDelaySeconds: 90
                    periodSeconds: 30
                    timeoutSeconds: 10
                    failureThreshold: 3
                  # ðŸ”§ Startup probe ì¶”ê°€ - ëŠë¦° ì‹œìž‘ í—ˆìš©
                  startupProbe:
                    httpGet:
                      path: /health
                      port: 8080
                    initialDelaySeconds: 10
                    periodSeconds: 10
                    timeoutSeconds: 5
                    failureThreshold: 30
          EOF
          
          kubectl apply -f inferenceservice.yaml
          echo "âœ… InferenceService applied"

      # ============================================================
      # ðŸ”§ ê°œì„ ëœ Pod Ready ìƒíƒœ ëŒ€ê¸° ë¡œì§
      # ============================================================
      - name: Wait for Pod to be Ready
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo "â³ Waiting for InferenceService to be ready..."
          
          MAX_RETRIES=60
          RETRY_INTERVAL=10
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            # InferenceService Ready ìƒíƒœ í™•ì¸
            READY=$(kubectl get inferenceservice california-housing-predictor \
              -n $NAMESPACE \
              -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "")
            
            if [ "$READY" = "True" ]; then
              echo "âœ… InferenceService is Ready!"
              break
            fi
            
            # Pod ìƒíƒœ ìƒì„¸ í™•ì¸
            echo "ðŸ“Š Current status (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES):"
            
            POD_NAME=$(kubectl get pods -n $NAMESPACE \
              -l serving.kserve.io/inferenceservice=california-housing-predictor \
              -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            
            if [ -n "$POD_NAME" ]; then
              POD_PHASE=$(kubectl get pod $POD_NAME -n $NAMESPACE -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
              CONTAINER_READY=$(kubectl get pod $POD_NAME -n $NAMESPACE -o jsonpath='{.status.containerStatuses[0].ready}' 2>/dev/null || echo "false")
              CONTAINER_STATE=$(kubectl get pod $POD_NAME -n $NAMESPACE -o jsonpath='{.status.containerStatuses[0].state}' 2>/dev/null || echo "{}")
              
              echo "  Pod: $POD_NAME"
              echo "  Phase: $POD_PHASE"
              echo "  Container Ready: $CONTAINER_READY"
              
              # Containerê°€ Runningì´ì§€ë§Œ Readyê°€ ì•„ë‹Œ ê²½ìš° (ì•± ì‹œìž‘ ì¤‘)
              if [ "$POD_PHASE" = "Running" ] && [ "$CONTAINER_READY" = "false" ]; then
                echo "  ðŸ“‹ Container is starting, checking logs..."
                kubectl logs $POD_NAME -n $NAMESPACE --tail=5 2>/dev/null || true
              fi
              
              # Pendingì¸ ê²½ìš° ì›ì¸ í™•ì¸
              if [ "$POD_PHASE" = "Pending" ]; then
                echo "  ðŸ“‹ Pending reason:"
                kubectl describe pod $POD_NAME -n $NAMESPACE 2>/dev/null | grep -A 3 "Events:" | tail -3 || true
              fi
            else
              echo "  No pods found yet..."
            fi
            
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "  Waiting ${RETRY_INTERVAL}s..."
            sleep $RETRY_INTERVAL
          done
          
          if [ $RETRY_COUNT -ge $MAX_RETRIES ]; then
            echo "âŒ Timeout waiting for InferenceService to be ready"
            echo "ðŸ“‹ Final Pod status:"
            kubectl get pods -n $NAMESPACE -l serving.kserve.io/inferenceservice=california-housing-predictor
            echo "ðŸ“‹ Pod description:"
            kubectl describe pods -n $NAMESPACE -l serving.kserve.io/inferenceservice=california-housing-predictor | tail -50
            echo "ðŸ“‹ Pod logs:"
            POD_NAME=$(kubectl get pods -n $NAMESPACE -l serving.kserve.io/inferenceservice=california-housing-predictor -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$POD_NAME" ]; then
              kubectl logs $POD_NAME -n $NAMESPACE --tail=100 2>/dev/null || true
            fi
            exit 1
          fi

      # ============================================================
      # ðŸ”§ ê°œì„ ëœ Health Check - ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œìž‘ ì™„ë£Œ ëŒ€ê¸°
      # ============================================================
      - name: Wait for Application to Start
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo "â³ Waiting for application to fully start inside container..."
          
          POD_NAME=$(kubectl get pods -n $NAMESPACE \
            -l serving.kserve.io/inferenceservice=california-housing-predictor \
            -o jsonpath='{.items[0].metadata.name}')
          
          echo "Pod: $POD_NAME"
          
          # Container ë‚´ë¶€ì—ì„œ ì§ì ‘ health check ì‹¤í–‰
          MAX_APP_RETRIES=30
          APP_RETRY_COUNT=0
          
          while [ $APP_RETRY_COUNT -lt $MAX_APP_RETRIES ]; do
            echo "ðŸ” Checking application health (attempt $((APP_RETRY_COUNT + 1))/$MAX_APP_RETRIES)..."
            
            # kubectl execë¡œ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ì§ì ‘ curl ì‹¤í–‰
            HEALTH_RESULT=$(kubectl exec -n $NAMESPACE $POD_NAME -- \
              curl -s -o /dev/null -w "%{http_code}" http://localhost:8080/health 2>/dev/null || echo "000")
            
            echo "  Health endpoint returned: $HEALTH_RESULT"
            
            if [ "$HEALTH_RESULT" = "200" ]; then
              echo "âœ… Application is healthy and ready!"
              
              # ì‹¤ì œ health ì‘ë‹µ ë‚´ìš© í™•ì¸
              kubectl exec -n $NAMESPACE $POD_NAME -- \
                curl -s http://localhost:8080/health 2>/dev/null || true
              break
            fi
            
            # ë¡œê·¸ í™•ì¸
            echo "  ðŸ“‹ Recent logs:"
            kubectl logs $POD_NAME -n $NAMESPACE --tail=3 2>/dev/null || true
            
            APP_RETRY_COUNT=$((APP_RETRY_COUNT + 1))
            echo "  Waiting 10s..."
            sleep 10
          done
          
          if [ $APP_RETRY_COUNT -ge $MAX_APP_RETRIES ]; then
            echo "âŒ Application failed to become healthy"
            echo "ðŸ“‹ Full Pod logs:"
            kubectl logs $POD_NAME -n $NAMESPACE --tail=100 2>/dev/null || true
            exit 1
          fi

      # ============================================================
      # ðŸ”§ ê°œì„ ëœ External Health Check (port-forward)
      # ============================================================
      - name: Test model endpoint via port-forward
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo "ðŸ§ª Testing model endpoint via port-forward..."
          
          POD_NAME=$(kubectl get pods -n $NAMESPACE \
            -l serving.kserve.io/inferenceservice=california-housing-predictor \
            -o jsonpath='{.items[0].metadata.name}')
          
          echo "Pod: $POD_NAME"
          
          # Port-forward ì‹œìž‘ (ë°±ê·¸ë¼ìš´ë“œ)
          kubectl port-forward -n $NAMESPACE pod/$POD_NAME 8000:8080 &
          PORT_FORWARD_PID=$!
          
          # Port-forwardê°€ ì„¤ì •ë  ë•Œê¹Œì§€ ì¶©ë¶„ížˆ ëŒ€ê¸°
          echo "â³ Waiting for port-forward to establish..."
          sleep 15
          
          # Health Check
          echo "Testing /health endpoint..."
          HEALTH_RESPONSE=$(curl -s --max-time 30 http://localhost:8000/health || echo '{"error": "connection failed"}')
          echo "Health response: $HEALTH_RESPONSE"
          
          # Prediction Test
          echo ""
          echo "Testing /predict endpoint..."
          PREDICT_RESPONSE=$(curl -s --max-time 30 -X POST http://localhost:8000/predict \
            -H "Content-Type: application/json" \
            -d '{"features":[8.3252,41.0,6.98,1.02,322.0,2.55,37.88,-122.23]}' || echo '{"error": "connection failed"}')
          echo "Prediction response: $PREDICT_RESPONSE"
          
          # Cleanup
          kill $PORT_FORWARD_PID 2>/dev/null || true
          
          # ê²°ê³¼ ê²€ì¦
          if echo "$HEALTH_RESPONSE" | grep -q '"status"'; then
            echo ""
            echo "âœ… Model deployment verified successfully!"
          else
            echo ""
            echo "âš ï¸  Health check response unexpected, but deployment may still be working"
            echo "    Check the InferenceService URL directly"
          fi

      - name: Show deployment info
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo ""
          echo "============================================================"
          echo "ðŸ“‹ Deployment Information"
          echo "============================================================"
          echo ""
          
          # InferenceService URL ê°€ì ¸ì˜¤ê¸°
          ISVC_URL=$(kubectl get inferenceservice california-housing-predictor \
            -n $NAMESPACE \
            -o jsonpath='{.status.url}' 2>/dev/null || echo "N/A")
          
          echo "InferenceService URL: $ISVC_URL"
          echo ""
          
          kubectl get inferenceservice california-housing-predictor -n $NAMESPACE
          echo ""
          kubectl get pods -n $NAMESPACE -l serving.kserve.io/inferenceservice=california-housing-predictor

      - name: Generate deployment summary
        if: always()
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          echo "## ðŸš€ Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Item | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Image | \`$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Timestamp | $(date -u '+%Y-%m-%d %H:%M:%S UTC') |" >> $GITHUB_STEP_SUMMARY
          echo "| Commit | ${{ github.sha }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Branch | ${{ github.ref_name }} |" >> $GITHUB_STEP_SUMMARY

      - name: Deployment instructions (if K8s not configured)
        if: steps.check-k8s.outputs.configured == 'false'
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          echo ""
          echo "============================================================"
          echo "ðŸ“¦ Image successfully pushed to ECR!"
          echo "============================================================"
          echo ""
          echo "To deploy manually to KServe:"
          echo ""
          echo "1. Configure KUBECONFIG_DATA secret in GitHub repository"
          echo "2. Ensure KServe is installed in your cluster"
          echo "3. Set KSERVE_NAMESPACE secret (default: kubeflow-user01)"
          echo ""
          echo "ðŸ’¡ For Lab 3-2, the monitoring stack is the main focus."
          echo "   KServe deployment is an optional advanced feature."