name: CD - Deploy Model

on:
  workflow_run:
    workflows: ["CI - Test Model"]
    types: [ completed ]
    branches: [ main ]

env:
  ECR_REPOSITORY: ml-model-california-housing
  AWS_REGION: ap-northeast-2

jobs:
  deploy:
    name: Build and Deploy Model
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      # ============================================================
      # ECR Repository ìƒì„± (ì¡´ìž¬í•˜ì§€ ì•Šì„ ê²½ìš°)
      # ============================================================
      - name: Create ECR Repository if not exists
        env:
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
        run: |
          echo "ðŸ” Checking if ECR repository exists..."
          
          if aws ecr describe-repositories --repository-names $ECR_REPOSITORY 2>/dev/null; then
            echo "âœ… ECR repository '$ECR_REPOSITORY' already exists"
          else
            echo "ðŸ“¦ Creating ECR repository '$ECR_REPOSITORY'..."
            aws ecr create-repository \
              --repository-name $ECR_REPOSITORY \
              --image-scanning-configuration scanOnPush=true \
              --image-tag-mutability MUTABLE \
              --encryption-configuration encryptionType=AES256
            
            echo "âœ… ECR repository created successfully"
          fi

      - name: Set image tag
        id: image-tag
        run: |
          SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)
          echo "tag=v$(date +%Y%m%d)-${SHORT_SHA}" >> $GITHUB_OUTPUT
          echo "timestamp=$(date +%Y%m%d-%H%M%S)" >> $GITHUB_OUTPUT

      - name: Check if Dockerfile exists
        id: check-dockerfile
        run: |
          if [ -f "Dockerfile" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "âœ… Dockerfile found in repository"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸  Dockerfile not found - will generate automatically"
          fi
      
      - name: Generate Dockerfile (if not exists)
        if: steps.check-dockerfile.outputs.exists == 'false'
        run: |
          echo "ðŸ“ Generating application files for California Housing model..."
          
          # Create api.py
          cat > api.py << 'APIEOF'
          from fastapi import FastAPI, HTTPException
          from pydantic import BaseModel, Field
          from typing import List
          import numpy as np
          from sklearn.datasets import fetch_california_housing
          from sklearn.ensemble import RandomForestRegressor
          from sklearn.model_selection import train_test_split
          import logging
          import os
          import time
          
          logging.basicConfig(level=logging.INFO)
          logger = logging.getLogger(__name__)
          
          app = FastAPI(
              title="California Housing Model API",
              description="ML model for California Housing price prediction",
              version=os.getenv("MODEL_VERSION", "1.0.0")
          )
          
          class PredictionInput(BaseModel):
              features: List[float] = Field(..., min_items=8, max_items=8)
          
          class PredictionOutput(BaseModel):
              prediction: float
              model_version: str
          
          model = None
          model_loaded = False
          
          @app.on_event("startup")
          async def load_model():
              global model, model_loaded
              start_time = time.time()
              logger.info("ðŸš€ Starting model loading...")
              
              try:
                  data = fetch_california_housing()
                  X_train, _, y_train, _ = train_test_split(
                      data.data, data.target, test_size=0.2, random_state=42
                  )
                  model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
                  model.fit(X_train, y_train)
                  model_loaded = True
                  elapsed = time.time() - start_time
                  logger.info(f"âœ… Model loaded successfully in {elapsed:.2f}s")
              except Exception as e:
                  logger.error(f"âŒ Model loading failed: {e}")
                  raise
          
          @app.get("/health")
          async def health():
              return {
                  "status": "healthy" if model_loaded else "loading",
                  "model_loaded": model_loaded
              }
          
          @app.get("/ready")
          async def ready():
              if not model_loaded:
                  raise HTTPException(status_code=503, detail="Model not ready")
              return {"status": "ready"}
          
          @app.post("/predict", response_model=PredictionOutput)
          async def predict(input_data: PredictionInput):
              if model is None or not model_loaded:
                  raise HTTPException(status_code=503, detail="Model not loaded")
              features = np.array(input_data.features).reshape(1, -1)
              prediction = model.predict(features)[0]
              return PredictionOutput(
                  prediction=float(prediction),
                  model_version=os.getenv("MODEL_VERSION", "1.0.0")
              )
          APIEOF
          
          # Create Dockerfile
          cat > Dockerfile << 'DOCKEREOF'
          FROM python:3.9-slim
          WORKDIR /app
          RUN pip install --no-cache-dir fastapi uvicorn scikit-learn numpy pydantic
          COPY api.py .
          ENV MODEL_VERSION=1.0.0
          EXPOSE 8080
          CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8080", "--timeout-keep-alive", "120"]
          DOCKEREOF
          
          echo "âœ… Generated api.py and Dockerfile"

      - name: Build Docker image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          echo "ðŸ”¨ Building Docker image..."
          docker build --platform linux/amd64 \
            --build-arg MODEL_VERSION=$IMAGE_TAG \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:latest \
            .
          echo "âœ… Image built: $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"

      - name: Push image to ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
          echo "âœ… Image pushed: $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"

      - name: Check Kubernetes configuration
        id: check-k8s
        run: |
          if [ -n "${{ secrets.KUBECONFIG_DATA }}" ]; then
            echo "configured=true" >> $GITHUB_OUTPUT
            echo "âœ… Kubernetes configuration available"
          else
            echo "configured=false" >> $GITHUB_OUTPUT
            echo "âš ï¸  KUBECONFIG_DATA not configured - skipping K8s deployment"
          fi

      - name: Set up kubectl
        if: steps.check-k8s.outputs.configured == 'true'
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
      
      - name: Install aws-iam-authenticator
        if: steps.check-k8s.outputs.configured == 'true'
        run: |
          echo "ðŸ“¦ Installing aws-iam-authenticator..."
          curl -Lo aws-iam-authenticator https://github.com/kubernetes-sigs/aws-iam-authenticator/releases/download/v0.6.11/aws-iam-authenticator_0.6.11_linux_amd64
          chmod +x ./aws-iam-authenticator
          sudo mv ./aws-iam-authenticator /usr/local/bin/
          aws-iam-authenticator version
          echo "âœ… aws-iam-authenticator installed"

      - name: Configure kubectl
        if: steps.check-k8s.outputs.configured == 'true'
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG_DATA }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          echo "âœ… kubectl configured"

      - name: Deploy to KServe
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo "ðŸš€ Deploying to KServe..."
          
          cat > inferenceservice.yaml << EOF
          apiVersion: serving.kserve.io/v1beta1
          kind: InferenceService
          metadata:
            name: california-housing-predictor
            namespace: $NAMESPACE
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            predictor:
              minReplicas: 1
              maxReplicas: 3
              containers:
                - name: predictor
                  image: $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
                  ports:
                    - containerPort: 8080
                      protocol: TCP
                  env:
                    - name: MODEL_VERSION
                      value: "$IMAGE_TAG"
                  resources:
                    requests:
                      cpu: "200m"
                      memory: "512Mi"
                    limits:
                      cpu: "1000m"
                      memory: "1Gi"
                  readinessProbe:
                    httpGet:
                      path: /health
                      port: 8080
                    initialDelaySeconds: 60
                    periodSeconds: 10
                    timeoutSeconds: 10
                    failureThreshold: 6
                  livenessProbe:
                    httpGet:
                      path: /health
                      port: 8080
                    initialDelaySeconds: 90
                    periodSeconds: 30
                    timeoutSeconds: 10
                    failureThreshold: 3
                  startupProbe:
                    httpGet:
                      path: /health
                      port: 8080
                    initialDelaySeconds: 10
                    periodSeconds: 10
                    timeoutSeconds: 5
                    failureThreshold: 30
          EOF
          
          kubectl apply -f inferenceservice.yaml
          echo "âœ… InferenceService applied"

      # ============================================================
      # ðŸ”§ í•µì‹¬ ìˆ˜ì •: kubectl wait ì‚¬ìš© (ê°€ìž¥ ì•ˆì •ì )
      # ============================================================
      - name: Wait for Pod to be Ready
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo "â³ Waiting for deployment to complete..."
          
          # 1. Podê°€ ìƒì„±ë  ë•Œê¹Œì§€ ëŒ€ê¸°
          echo "ðŸ“‹ Step 1: Waiting for Pod to be created..."
          MAX_WAIT=60
          WAITED=0
          while [ $WAITED -lt $MAX_WAIT ]; do
            POD_NAME=$(kubectl get pods -n $NAMESPACE \
              -l serving.kserve.io/inferenceservice=california-housing-predictor \
              -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            
            if [ -n "$POD_NAME" ]; then
              echo "âœ… Pod found: $POD_NAME"
              break
            fi
            
            echo "  Waiting for Pod to be created... ($WAITED/$MAX_WAIT)"
            sleep 5
            WAITED=$((WAITED + 5))
          done
          
          if [ -z "$POD_NAME" ]; then
            echo "âŒ Pod not created within timeout"
            kubectl get all -n $NAMESPACE
            exit 1
          fi
          
          # 2. kubectl waitë¡œ Pod Ready ìƒíƒœ ëŒ€ê¸° (ê°€ìž¥ ì•ˆì •ì ì¸ ë°©ë²•)
          echo ""
          echo "ðŸ“‹ Step 2: Waiting for Pod to be Ready (readinessProbe í†µê³¼)..."
          echo "   This waits for Kubernetes readinessProbe to succeed."
          echo "   (The probe is checking /health endpoint internally)"
          echo ""
          
          if kubectl wait --for=condition=Ready pod/$POD_NAME -n $NAMESPACE --timeout=600s; then
            echo ""
            echo "âœ… Pod is Ready! (readinessProbe passed)"
          else
            echo ""
            echo "âŒ Pod failed to become Ready"
            echo ""
            echo "ðŸ“‹ Pod Status:"
            kubectl get pod $POD_NAME -n $NAMESPACE -o wide
            echo ""
            echo "ðŸ“‹ Pod Events:"
            kubectl describe pod $POD_NAME -n $NAMESPACE | tail -30
            echo ""
            echo "ðŸ“‹ Pod Logs:"
            kubectl logs $POD_NAME -n $NAMESPACE --tail=50 || true
            exit 1
          fi
          
          # 3. InferenceService Ready ìƒíƒœ í™•ì¸
          echo ""
          echo "ðŸ“‹ Step 3: Checking InferenceService status..."
          kubectl get inferenceservice california-housing-predictor -n $NAMESPACE

      # ============================================================
      # ðŸ”§ ìˆ˜ì •: Python urllib ì‚¬ìš© (curl ëŒ€ì‹ )
      # ============================================================
      - name: Verify application health (inside container)
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo "ðŸ” Verifying application health from inside container..."
          
          POD_NAME=$(kubectl get pods -n $NAMESPACE \
            -l serving.kserve.io/inferenceservice=california-housing-predictor \
            -o jsonpath='{.items[0].metadata.name}')
          
          echo "Pod: $POD_NAME"
          echo ""
          
          # Python urllib ì‚¬ìš© (curlì´ ì—†ìœ¼ë¯€ë¡œ)
          echo "ðŸ“‹ Health Check (using Python urllib):"
          kubectl exec -n $NAMESPACE $POD_NAME -- \
            python -c "
          import urllib.request
          import json
          try:
              response = urllib.request.urlopen('http://localhost:8080/health', timeout=10)
              data = json.loads(response.read().decode())
              print(json.dumps(data, indent=2))
              if data.get('model_loaded'):
                  print('âœ… Model is loaded and ready!')
              else:
                  print('âš ï¸ Model is still loading...')
          except Exception as e:
              print(f'Error: {e}')
              exit(1)
          "
          
          echo ""
          echo "ðŸ“‹ Prediction Test (using Python urllib):"
          kubectl exec -n $NAMESPACE $POD_NAME -- \
            python -c "
          import urllib.request
          import json
          try:
              data = json.dumps({'features': [8.3252, 41.0, 6.98, 1.02, 322.0, 2.55, 37.88, -122.23]}).encode()
              req = urllib.request.Request(
                  'http://localhost:8080/predict',
                  data=data,
                  headers={'Content-Type': 'application/json'}
              )
              response = urllib.request.urlopen(req, timeout=30)
              result = json.loads(response.read().decode())
              print(json.dumps(result, indent=2))
              print('âœ… Prediction successful!')
          except Exception as e:
              print(f'Error: {e}')
              exit(1)
          "

      # ============================================================
      # Port-forward í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­ - ì™¸ë¶€ ì ‘ê·¼ í™•ì¸)
      # ============================================================
      - name: Test via port-forward (optional external check)
        if: steps.check-k8s.outputs.configured == 'true'
        continue-on-error: true
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo "ðŸ§ª Testing via port-forward (external access)..."
          echo "   Note: This may fail in some network configurations."
          echo ""
          
          POD_NAME=$(kubectl get pods -n $NAMESPACE \
            -l serving.kserve.io/inferenceservice=california-housing-predictor \
            -o jsonpath='{.items[0].metadata.name}')
          
          # Port-forward ì‹œìž‘
          kubectl port-forward -n $NAMESPACE pod/$POD_NAME 8000:8080 &
          PORT_FORWARD_PID=$!
          sleep 10
          
          # Health Check
          echo "Testing /health endpoint..."
          HEALTH_RESPONSE=$(curl -s --max-time 30 http://localhost:8000/health 2>/dev/null || echo '{"error": "connection failed"}')
          echo "Response: $HEALTH_RESPONSE"
          
          # Cleanup
          kill $PORT_FORWARD_PID 2>/dev/null || true
          
          if echo "$HEALTH_RESPONSE" | grep -q '"model_loaded": true'; then
            echo "âœ… Port-forward test passed!"
          else
            echo "âš ï¸ Port-forward test inconclusive (may be network restriction)"
            echo "   Internal health check already passed, deployment is successful."
          fi

      - name: Show deployment info
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo ""
          echo "============================================================"
          echo "ðŸ“‹ Deployment Summary"
          echo "============================================================"
          echo ""
          
          ISVC_URL=$(kubectl get inferenceservice california-housing-predictor \
            -n $NAMESPACE \
            -o jsonpath='{.status.url}' 2>/dev/null || echo "N/A")
          
          echo "InferenceService URL: $ISVC_URL"
          echo ""
          echo "InferenceService Status:"
          kubectl get inferenceservice california-housing-predictor -n $NAMESPACE
          echo ""
          echo "Pod Status:"
          kubectl get pods -n $NAMESPACE -l serving.kserve.io/inferenceservice=california-housing-predictor -o wide
          echo ""
          echo "============================================================"
          echo "âœ… Deployment completed successfully!"
          echo "============================================================"

      - name: Generate deployment summary
        if: always()
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          echo "## ðŸš€ Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Item | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Image | \`$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Timestamp | $(date -u '+%Y-%m-%d %H:%M:%S UTC') |" >> $GITHUB_STEP_SUMMARY
          echo "| Commit | ${{ github.sha }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Branch | ${{ github.ref_name }} |" >> $GITHUB_STEP_SUMMARY

      - name: Deployment instructions (if K8s not configured)
        if: steps.check-k8s.outputs.configured == 'false'
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          echo ""
          echo "============================================================"
          echo "ðŸ“¦ Image successfully pushed to ECR!"
          echo "============================================================"
          echo ""
          echo "To deploy manually to KServe:"
          echo "1. Configure KUBECONFIG_DATA secret in GitHub repository"
          echo "2. Ensure KServe is installed in your cluster"
          echo "3. Set KSERVE_NAMESPACE secret (default: kubeflow-user01)"