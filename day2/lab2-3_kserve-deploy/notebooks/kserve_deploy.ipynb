{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2-3: KServe ë°°í¬ (Jupyter Notebook)\n",
    "\n",
    "## ğŸ“‹ ì‹¤ìŠµ ê°œìš”\n",
    "\n",
    "| í•­ëª© | ë‚´ìš© |\n",
    "|------|------|\n",
    "| **ì†Œìš”ì‹œê°„** | 40ë¶„ |\n",
    "| **ë‚œì´ë„** | â­â­â­ |\n",
    "| **ëª©í‘œ** | KServeë¡œ í”„ë¡œë•ì…˜ ëª¨ë¸ ì„œë¹™ |\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "- KServe InferenceService ì´í•´\n",
    "- Pythonìœ¼ë¡œ Kubernetes ë¦¬ì†ŒìŠ¤ ìƒì„±\n",
    "- S3ì—ì„œ ëª¨ë¸ ë¡œë“œ\n",
    "- REST APIë¥¼ í†µí•œ ì¶”ë¡ \n",
    "\n",
    "---\n",
    "\n",
    "Â© 2025 í˜„ëŒ€ì˜¤í† ì—ë²„ MLOps Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install kubernetes requests boto3 mlflow -q\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client, config\n",
    "from kubernetes.client.rest import ApiException\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import base64\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Kubernetes í´ë¼ì´ì–¸íŠ¸ ì—°ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#                     Kubernetes ì—°ê²° ì„¤ì •\n",
    "# ======================================================================\n",
    "\n",
    "def connect_kubernetes():\n",
    "    \"\"\"\n",
    "    Kubernetes í´ëŸ¬ìŠ¤í„°ì— ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "    - Kubeflow ë‚´ë¶€: load_incluster_config() ì‚¬ìš©\n",
    "    - ë¡œì»¬: load_kube_config() ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Kubeflow ë‚´ë¶€ (Kubernetes Pod ë‚´ë¶€)\n",
    "        config.load_incluster_config()\n",
    "        print(\"ğŸ¢ í™˜ê²½: Kubeflow Notebook (Kubernetes í´ëŸ¬ìŠ¤í„° ë‚´ë¶€)\")\n",
    "        return \"incluster\"\n",
    "    except config.ConfigException:\n",
    "        # ë¡œì»¬ í™˜ê²½\n",
    "        config.load_kube_config()\n",
    "        print(\"ğŸ’» í™˜ê²½: ë¡œì»¬ (kubeconfig ì‚¬ìš©)\")\n",
    "        return \"local\"\n",
    "\n",
    "# ì—°ê²° ì‹¤í–‰\n",
    "env_type = connect_kubernetes()\n",
    "\n",
    "# API í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "core_v1 = client.CoreV1Api()\n",
    "custom_api = client.CustomObjectsApi()\n",
    "\n",
    "# ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "try:\n",
    "    namespaces = core_v1.list_namespace()\n",
    "    print(f\"âœ… Kubernetes ì—°ê²° ì„±ê³µ! ({len(namespaces.items)}ê°œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë°œê²¬)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì—°ê²° ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 ì‚¬ìš©ì ì„¤ì •\n",
    "\n",
    "âš ï¸ **ì¤‘ìš”**: ì•„ë˜ ì„¤ì •ì„ ë³¸ì¸ì˜ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#                     âš ï¸ ì‚¬ìš©ì ì„¤ì • (ìˆ˜ì • í•„ìš”!)\n",
    "# ======================================================================\n",
    "\n",
    "# ìˆ˜ê°•ìƒ ë²ˆí˜¸ (01 ~ 30)\n",
    "USER_NUM = \"01\"  # â† ë³¸ì¸ ë²ˆí˜¸ë¡œ ë³€ê²½!\n",
    "\n",
    "# AWS ìê²©ì¦ëª… (ê°•ì‚¬ ì•ˆë‚´ ì°¸ì¡°)\n",
    "AWS_ACCESS_KEY_ID = \"YOUR_ACCESS_KEY\"       # â† ìˆ˜ì • í•„ìš”!\n",
    "AWS_SECRET_ACCESS_KEY = \"YOUR_SECRET_KEY\"   # â† ìˆ˜ì • í•„ìš”!\n",
    "AWS_REGION = \"ap-northeast-2\"\n",
    "\n",
    "# MLflow Run ID (Lab 2-2ì—ì„œ í™•ì¸)\n",
    "MLFLOW_RUN_ID = \"YOUR-RUN-ID\"  # â† MLflow UIì—ì„œ ë³µì‚¬!\n",
    "\n",
    "# ======================================================================\n",
    "#                     ìë™ ì„¤ì • (ìˆ˜ì • ë¶ˆí•„ìš”)\n",
    "# ======================================================================\n",
    "\n",
    "NAMESPACE = f\"kubeflow-user{USER_NUM}\"\n",
    "MODEL_NAME = \"california-model\"\n",
    "S3_BUCKET = f\"mlops-training-user{USER_NUM}\"\n",
    "MODEL_URI = f\"s3://{S3_BUCKET}/mlflow-artifacts/1/{MLFLOW_RUN_ID}/artifacts/model\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  ì‚¬ìš©ì ì„¤ì • í™•ì¸\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  ğŸ‘¤ ì‚¬ìš©ì: user{USER_NUM}\")\n",
    "print(f\"  ğŸ“¦ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {NAMESPACE}\")\n",
    "print(f\"  ğŸ¤– ëª¨ë¸ ì´ë¦„: {MODEL_NAME}\")\n",
    "print(f\"  ğŸª£ S3 ë²„í‚·: {S3_BUCKET}\")\n",
    "print(f\"  ğŸ“ ëª¨ë¸ ê²½ë¡œ: {MODEL_URI}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. AWS ìê²©ì¦ëª… ì„¤ì •\n",
    "\n",
    "KServeê°€ S3ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ê¸° ìœ„í•´ AWS ìê²©ì¦ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **Secret**: AWS Access Key, Secret Key ì €ì¥\n",
    "- **ConfigMap**: S3 ì—”ë“œí¬ì¸íŠ¸, ë¦¬ì „ ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 AWS Secret ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 2.1: AWS Secret ìƒì„± (setup_credentials.sh ëŒ€ì²´)\n",
    "# ======================================================================\n",
    "\n",
    "def create_aws_secret(namespace, access_key, secret_key, region):\n",
    "    \"\"\"\n",
    "    AWS ìê²©ì¦ëª… Secretì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ê¸°ì¡´ setup_credentials.shì˜ ë‹¤ìŒ ëª…ë ¹ì„ ëŒ€ì²´í•©ë‹ˆë‹¤:\n",
    "    kubectl create secret generic aws-s3-credentials ...\n",
    "    \"\"\"\n",
    "    secret_name = \"aws-s3-credentials\"\n",
    "    \n",
    "    # Secret ì •ì˜\n",
    "    secret = client.V1Secret(\n",
    "        api_version=\"v1\",\n",
    "        kind=\"Secret\",\n",
    "        metadata=client.V1ObjectMeta(\n",
    "            name=secret_name,\n",
    "            namespace=namespace\n",
    "        ),\n",
    "        type=\"Opaque\",\n",
    "        string_data={\n",
    "            \"AWS_ACCESS_KEY_ID\": access_key,\n",
    "            \"AWS_SECRET_ACCESS_KEY\": secret_key,\n",
    "            \"AWS_DEFAULT_REGION\": region\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # ê¸°ì¡´ Secret ì‚­ì œ (ìˆìœ¼ë©´)\n",
    "        core_v1.delete_namespaced_secret(secret_name, namespace)\n",
    "        print(f\"  ğŸ—‘ï¸  ê¸°ì¡´ Secret '{secret_name}' ì‚­ì œ\")\n",
    "    except ApiException as e:\n",
    "        if e.status != 404:\n",
    "            raise\n",
    "    \n",
    "    # ìƒˆ Secret ìƒì„±\n",
    "    core_v1.create_namespaced_secret(namespace, secret)\n",
    "    print(f\"  âœ… Secret '{secret_name}' ìƒì„± ì™„ë£Œ!\")\n",
    "    \n",
    "    return secret_name\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  AWS Secret ìƒì„±\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Secret ìƒì„± ì‹¤í–‰\n",
    "secret_name = create_aws_secret(\n",
    "    namespace=NAMESPACE,\n",
    "    access_key=AWS_ACCESS_KEY_ID,\n",
    "    secret_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region=AWS_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 S3 ConfigMap ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 2.2: S3 ConfigMap ìƒì„±\n",
    "# ======================================================================\n",
    "\n",
    "def create_s3_configmap(namespace):\n",
    "    \"\"\"\n",
    "    S3 ì„¤ì • ConfigMapì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ê¸°ì¡´ setup_credentials.shì˜ ë‹¤ìŒ ëª…ë ¹ì„ ëŒ€ì²´í•©ë‹ˆë‹¤:\n",
    "    kubectl create configmap s3-config ...\n",
    "    \"\"\"\n",
    "    configmap_name = \"s3-config\"\n",
    "    \n",
    "    # ConfigMap ì •ì˜\n",
    "    configmap = client.V1ConfigMap(\n",
    "        api_version=\"v1\",\n",
    "        kind=\"ConfigMap\",\n",
    "        metadata=client.V1ObjectMeta(\n",
    "            name=configmap_name,\n",
    "            namespace=namespace\n",
    "        ),\n",
    "        data={\n",
    "            \"S3_ENDPOINT\": \"s3.amazonaws.com\",\n",
    "            \"S3_USE_HTTPS\": \"1\",\n",
    "            \"AWS_REGION\": \"ap-northeast-2\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # ê¸°ì¡´ ConfigMap ì‚­ì œ (ìˆìœ¼ë©´)\n",
    "        core_v1.delete_namespaced_config_map(configmap_name, namespace)\n",
    "        print(f\"  ğŸ—‘ï¸  ê¸°ì¡´ ConfigMap '{configmap_name}' ì‚­ì œ\")\n",
    "    except ApiException as e:\n",
    "        if e.status != 404:\n",
    "            raise\n",
    "    \n",
    "    # ìƒˆ ConfigMap ìƒì„±\n",
    "    core_v1.create_namespaced_config_map(namespace, configmap)\n",
    "    print(f\"  âœ… ConfigMap '{configmap_name}' ìƒì„± ì™„ë£Œ!\")\n",
    "    \n",
    "    return configmap_name\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  S3 ConfigMap ìƒì„±\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ConfigMap ìƒì„± ì‹¤í–‰\n",
    "configmap_name = create_s3_configmap(NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ìê²©ì¦ëª… í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 2.3: ìê²©ì¦ëª… í™•ì¸\n",
    "# ======================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  ìê²©ì¦ëª… í™•ì¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Secret í™•ì¸\n",
    "try:\n",
    "    secret = core_v1.read_namespaced_secret(\"aws-s3-credentials\", NAMESPACE)\n",
    "    print(f\"  âœ… Secret 'aws-s3-credentials' ì¡´ì¬\")\n",
    "    print(f\"     - Keys: {list(secret.data.keys())}\")\n",
    "except ApiException:\n",
    "    print(f\"  âŒ Secret 'aws-s3-credentials' ì—†ìŒ\")\n",
    "\n",
    "# ConfigMap í™•ì¸\n",
    "try:\n",
    "    cm = core_v1.read_namespaced_config_map(\"s3-config\", NAMESPACE)\n",
    "    print(f\"  âœ… ConfigMap 's3-config' ì¡´ì¬\")\n",
    "    print(f\"     - Keys: {list(cm.data.keys())}\")\n",
    "except ApiException:\n",
    "    print(f\"  âŒ ConfigMap 's3-config' ì—†ìŒ\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. InferenceService ë°°í¬\n",
    "\n",
    "KServe InferenceServiceë¥¼ ìƒì„±í•˜ì—¬ ëª¨ë¸ì„ ë°°í¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 InferenceService ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 3.1: InferenceService ì •ì˜ (manifests/inferenceservice.yaml ëŒ€ì²´)\n",
    "# ======================================================================\n",
    "\n",
    "def create_inferenceservice_spec(model_name, namespace, storage_uri):\n",
    "    \"\"\"\n",
    "    KServe InferenceService ìŠ¤í™ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ê¸°ì¡´ manifests/inferenceservice.yamlì„ Python dictë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    inference_service = {\n",
    "        \"apiVersion\": \"serving.kserve.io/v1beta1\",\n",
    "        \"kind\": \"InferenceService\",\n",
    "        \"metadata\": {\n",
    "            \"name\": model_name,\n",
    "            \"namespace\": namespace,\n",
    "            \"annotations\": {\n",
    "                \"serving.kserve.io/s3-endpoint\": \"s3.amazonaws.com\",\n",
    "                \"serving.kserve.io/s3-region\": \"ap-northeast-2\",\n",
    "                \"serving.kserve.io/s3-usehttps\": \"1\",\n",
    "                \"serving.kserve.io/s3-useanoncredential\": \"false\"\n",
    "            }\n",
    "        },\n",
    "        \"spec\": {\n",
    "            \"predictor\": {\n",
    "                \"serviceAccountName\": \"default\",\n",
    "                \"model\": {\n",
    "                    \"modelFormat\": {\n",
    "                        \"name\": \"sklearn\"\n",
    "                    },\n",
    "                    \"storageUri\": storage_uri,\n",
    "                    \"resources\": {\n",
    "                        \"requests\": {\n",
    "                            \"memory\": \"512Mi\",\n",
    "                            \"cpu\": \"500m\"\n",
    "                        },\n",
    "                        \"limits\": {\n",
    "                            \"memory\": \"1Gi\",\n",
    "                            \"cpu\": \"1000m\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"env\": [\n",
    "                        {\n",
    "                            \"name\": \"AWS_ACCESS_KEY_ID\",\n",
    "                            \"valueFrom\": {\n",
    "                                \"secretKeyRef\": {\n",
    "                                    \"name\": \"aws-s3-credentials\",\n",
    "                                    \"key\": \"AWS_ACCESS_KEY_ID\"\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"AWS_SECRET_ACCESS_KEY\",\n",
    "                            \"valueFrom\": {\n",
    "                                \"secretKeyRef\": {\n",
    "                                    \"name\": \"aws-s3-credentials\",\n",
    "                                    \"key\": \"AWS_SECRET_ACCESS_KEY\"\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"AWS_DEFAULT_REGION\",\n",
    "                            \"valueFrom\": {\n",
    "                                \"secretKeyRef\": {\n",
    "                                    \"name\": \"aws-s3-credentials\",\n",
    "                                    \"key\": \"AWS_DEFAULT_REGION\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return inference_service\n",
    "\n",
    "# InferenceService ìŠ¤í™ ìƒì„±\n",
    "isvc_spec = create_inferenceservice_spec(MODEL_NAME, NAMESPACE, MODEL_URI)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  InferenceService ìŠ¤í™\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(isvc_spec, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 InferenceService ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 3.2: InferenceService ë°°í¬ (deploy_kserve.sh ëŒ€ì²´)\n",
    "# ======================================================================\n",
    "\n",
    "def deploy_inferenceservice(isvc_spec, namespace):\n",
    "    \"\"\"\n",
    "    KServe InferenceServiceë¥¼ ë°°í¬í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ê¸°ì¡´ deploy_kserve.shì˜ ë‹¤ìŒ ëª…ë ¹ì„ ëŒ€ì²´í•©ë‹ˆë‹¤:\n",
    "    kubectl apply -f manifests/inferenceservice.yaml\n",
    "    \"\"\"\n",
    "    model_name = isvc_spec[\"metadata\"][\"name\"]\n",
    "    \n",
    "    print(f\"  ğŸ“¦ InferenceService '{model_name}' ë°°í¬ ì¤‘...\")\n",
    "    \n",
    "    # ê¸°ì¡´ InferenceService ì‚­ì œ (ìˆìœ¼ë©´)\n",
    "    try:\n",
    "        custom_api.delete_namespaced_custom_object(\n",
    "            group=\"serving.kserve.io\",\n",
    "            version=\"v1beta1\",\n",
    "            namespace=namespace,\n",
    "            plural=\"inferenceservices\",\n",
    "            name=model_name\n",
    "        )\n",
    "        print(f\"  ğŸ—‘ï¸  ê¸°ì¡´ InferenceService '{model_name}' ì‚­ì œ\")\n",
    "        time.sleep(5)  # ì‚­ì œ ì™„ë£Œ ëŒ€ê¸°\n",
    "    except ApiException as e:\n",
    "        if e.status != 404:\n",
    "            raise\n",
    "    \n",
    "    # ìƒˆ InferenceService ìƒì„±\n",
    "    custom_api.create_namespaced_custom_object(\n",
    "        group=\"serving.kserve.io\",\n",
    "        version=\"v1beta1\",\n",
    "        namespace=namespace,\n",
    "        plural=\"inferenceservices\",\n",
    "        body=isvc_spec\n",
    "    )\n",
    "    \n",
    "    print(f\"  âœ… InferenceService '{model_name}' ìƒì„± ì™„ë£Œ!\")\n",
    "    return model_name\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  InferenceService ë°°í¬\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ë°°í¬ ì‹¤í–‰\n",
    "deploy_inferenceservice(isvc_spec, NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ë°°í¬ ìƒíƒœ ëª¨ë‹ˆí„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 3.3: ë°°í¬ ìƒíƒœ ëª¨ë‹ˆí„°ë§\n",
    "# ======================================================================\n",
    "\n",
    "def wait_for_inferenceservice(model_name, namespace, timeout=300):\n",
    "    \"\"\"\n",
    "    InferenceServiceê°€ Ready ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ê¸°ì¡´ deploy_kserve.shì˜ ë‹¤ìŒ ëª…ë ¹ì„ ëŒ€ì²´í•©ë‹ˆë‹¤:\n",
    "    kubectl wait --for=condition=Ready inferenceservice/california-model ...\n",
    "    \"\"\"\n",
    "    print(f\"  â³ InferenceService '{model_name}' Ready ëŒ€ê¸° ì¤‘...\")\n",
    "    print(f\"     (ìµœëŒ€ {timeout}ì´ˆ, ë³´í†µ 2-3ë¶„ ì†Œìš”)\")\n",
    "    print()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < timeout:\n",
    "        try:\n",
    "            isvc = custom_api.get_namespaced_custom_object(\n",
    "                group=\"serving.kserve.io\",\n",
    "                version=\"v1beta1\",\n",
    "                namespace=namespace,\n",
    "                plural=\"inferenceservices\",\n",
    "                name=model_name\n",
    "            )\n",
    "            \n",
    "            # ìƒíƒœ í™•ì¸\n",
    "            conditions = isvc.get(\"status\", {}).get(\"conditions\", [])\n",
    "            ready_condition = next(\n",
    "                (c for c in conditions if c.get(\"type\") == \"Ready\"), \n",
    "                None\n",
    "            )\n",
    "            \n",
    "            elapsed = int(time.time() - start_time)\n",
    "            \n",
    "            if ready_condition:\n",
    "                status = ready_condition.get(\"status\", \"Unknown\")\n",
    "                reason = ready_condition.get(\"reason\", \"\")\n",
    "                \n",
    "                if status == \"True\":\n",
    "                    print(f\"  âœ… InferenceService READY! ({elapsed}ì´ˆ ì†Œìš”)\")\n",
    "                    return True\n",
    "                else:\n",
    "                    print(f\"  â³ Status: {status} | Reason: {reason} ({elapsed}ì´ˆ)\")\n",
    "            else:\n",
    "                print(f\"  â³ ìƒíƒœ í™•ì¸ ì¤‘... ({elapsed}ì´ˆ)\")\n",
    "            \n",
    "        except ApiException as e:\n",
    "            print(f\"  âš ï¸  ì¡°íšŒ ì‹¤íŒ¨: {e.reason}\")\n",
    "        \n",
    "        time.sleep(10)\n",
    "    \n",
    "    print(f\"  âŒ íƒ€ì„ì•„ì›ƒ! ({timeout}ì´ˆ ì´ˆê³¼)\")\n",
    "    return False\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  ë°°í¬ ìƒíƒœ ëª¨ë‹ˆí„°ë§\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ready ìƒíƒœ ëŒ€ê¸°\n",
    "is_ready = wait_for_inferenceservice(MODEL_NAME, NAMESPACE, timeout=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 InferenceService ìƒíƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 3.4: InferenceService ìƒíƒœ í™•ì¸\n",
    "# ======================================================================\n",
    "\n",
    "def get_inferenceservice_status(model_name, namespace):\n",
    "    \"\"\"\n",
    "    InferenceService ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ê¸°ì¡´ deploy_kserve.shì˜ ë‹¤ìŒ ëª…ë ¹ì„ ëŒ€ì²´í•©ë‹ˆë‹¤:\n",
    "    kubectl get inferenceservice -n $NAMESPACE\n",
    "    \"\"\"\n",
    "    try:\n",
    "        isvc = custom_api.get_namespaced_custom_object(\n",
    "            group=\"serving.kserve.io\",\n",
    "            version=\"v1beta1\",\n",
    "            namespace=namespace,\n",
    "            plural=\"inferenceservices\",\n",
    "            name=model_name\n",
    "        )\n",
    "        \n",
    "        # ìƒíƒœ ì •ë³´ ì¶”ì¶œ\n",
    "        status = isvc.get(\"status\", {})\n",
    "        conditions = status.get(\"conditions\", [])\n",
    "        url = status.get(\"url\", \"N/A\")\n",
    "        address = status.get(\"address\", {}).get(\"url\", \"N/A\")\n",
    "        \n",
    "        print(f\"  ğŸ“Š InferenceService ìƒíƒœ\")\n",
    "        print(f\"  \" + \"-\"*50)\n",
    "        print(f\"  Name: {model_name}\")\n",
    "        print(f\"  Namespace: {namespace}\")\n",
    "        print()\n",
    "        print(f\"  Conditions:\")\n",
    "        for cond in conditions:\n",
    "            ctype = cond.get(\"type\", \"Unknown\")\n",
    "            cstatus = cond.get(\"status\", \"Unknown\")\n",
    "            symbol = \"âœ…\" if cstatus == \"True\" else \"â³\" if cstatus == \"Unknown\" else \"âŒ\"\n",
    "            print(f\"    {symbol} {ctype}: {cstatus}\")\n",
    "        \n",
    "        print()\n",
    "        print(f\"  URLs:\")\n",
    "        print(f\"    External: {url}\")\n",
    "        print(f\"    Internal: {address}\")\n",
    "        \n",
    "        return isvc\n",
    "        \n",
    "    except ApiException as e:\n",
    "        print(f\"  âŒ ì¡°íšŒ ì‹¤íŒ¨: {e.reason}\")\n",
    "        return None\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  InferenceService ìƒíƒœ í™•ì¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "isvc_status = get_inferenceservice_status(MODEL_NAME, NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Pod ìƒíƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 3.5: Pod ìƒíƒœ í™•ì¸\n",
    "# ======================================================================\n",
    "\n",
    "def get_model_pods(model_name, namespace):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ ì„œë¹™ Pod ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ê¸°ì¡´ deploy_kserve.shì˜ ë‹¤ìŒ ëª…ë ¹ì„ ëŒ€ì²´í•©ë‹ˆë‹¤:\n",
    "    kubectl get pods -n $NAMESPACE -l serving.kserve.io/inferenceservice=$MODEL_NAME\n",
    "    \"\"\"\n",
    "    label_selector = f\"serving.kserve.io/inferenceservice={model_name}\"\n",
    "    \n",
    "    pods = core_v1.list_namespaced_pod(\n",
    "        namespace=namespace,\n",
    "        label_selector=label_selector\n",
    "    )\n",
    "    \n",
    "    print(f\"  ğŸ“¦ ëª¨ë¸ ì„œë¹™ Pod ëª©ë¡\")\n",
    "    print(f\"  \" + \"-\"*50)\n",
    "    \n",
    "    if not pods.items:\n",
    "        print(f\"  âš ï¸  Podë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    for pod in pods.items:\n",
    "        name = pod.metadata.name\n",
    "        phase = pod.status.phase\n",
    "        symbol = \"âœ…\" if phase == \"Running\" else \"â³\" if phase == \"Pending\" else \"âŒ\"\n",
    "        \n",
    "        # Container ìƒíƒœ\n",
    "        containers = []\n",
    "        for cs in (pod.status.container_statuses or []):\n",
    "            ready = \"Ready\" if cs.ready else \"NotReady\"\n",
    "            containers.append(f\"{cs.name}:{ready}\")\n",
    "        \n",
    "        print(f\"  {symbol} {name}\")\n",
    "        print(f\"     Phase: {phase}\")\n",
    "        print(f\"     Containers: {', '.join(containers) if containers else 'N/A'}\")\n",
    "    \n",
    "    return pods.items[0] if pods.items else None\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  Pod ìƒíƒœ í™•ì¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_pod = get_model_pods(MODEL_NAME, NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ì¶”ë¡  í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ë°°í¬ëœ ëª¨ë¸ì— REST APIë¡œ ì¶”ë¡  ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 4.1: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
    "# ======================================================================\n",
    "\n",
    "# California Housing ë°ì´í„°ì…‹ í”¼ì²˜ (8ê°œ)\n",
    "# [MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude]\n",
    "\n",
    "test_data = {\n",
    "    \"instances\": [\n",
    "        [8.3252, 41.0, 6.984, 1.024, 322.0, 2.556, 37.88, -122.23],  # ìƒ˜í”Œ 1\n",
    "        [5.6431, 52.0, 5.817, 1.073, 558.0, 2.547, 37.85, -122.25],  # ìƒ˜í”Œ 2\n",
    "        [3.8462, 35.0, 6.238, 1.058, 1212.0, 2.689, 37.87, -122.24]  # ìƒ˜í”Œ 3\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  í…ŒìŠ¤íŠ¸ ë°ì´í„°\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  í”¼ì²˜: [MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Lat, Lon]\")\n",
    "print()\n",
    "for i, instance in enumerate(test_data[\"instances\"]):\n",
    "    print(f\"  ìƒ˜í”Œ {i+1}: {instance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ì¶”ë¡  í…ŒìŠ¤íŠ¸ (Kubeflow í™˜ê²½)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 4.2: í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ì¶”ë¡  í…ŒìŠ¤íŠ¸\n",
    "# ======================================================================\n",
    "\n",
    "def test_inference_internal(model_name, namespace, test_data):\n",
    "    \"\"\"\n",
    "    í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ì—ì„œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    Kubeflow Notebook í™˜ê²½ì—ì„œ ì‹¤í–‰ ì‹œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ì„œë¹„ìŠ¤ URL\n",
    "    url = f\"http://{model_name}.{namespace}.svc.cluster.local/v1/models/{model_name}:predict\"\n",
    "    \n",
    "    print(f\"  ğŸŒ ì¶”ë¡  URL: {url}\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            json=test_data,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"  âœ… ì¶”ë¡  ì„±ê³µ!\")\n",
    "            print()\n",
    "            print(f\"  ğŸ“Š ê²°ê³¼:\")\n",
    "            predictions = result.get(\"predictions\", [])\n",
    "            for i, pred in enumerate(predictions):\n",
    "                print(f\"    ìƒ˜í”Œ {i+1}: ${pred*100000:,.0f} (ì˜ˆì¸¡ ì£¼íƒ ê°€ê²©)\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"  âŒ ì¶”ë¡  ì‹¤íŒ¨: HTTP {response.status_code}\")\n",
    "            print(f\"     {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"  âš ï¸  ì—°ê²° ì‹¤íŒ¨ (í´ëŸ¬ìŠ¤í„° ì™¸ë¶€ í™˜ê²½ì¼ ìˆ˜ ìˆìŒ)\")\n",
    "        print(f\"     â†’ ë‹¤ìŒ ì…€ì˜ 'í¬íŠ¸ í¬ì›Œë”©' ë°©ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ì¶”ë¡  í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "if env_type == \"incluster\":\n",
    "    result = test_inference_internal(MODEL_NAME, NAMESPACE, test_data)\n",
    "else:\n",
    "    print(\"  â„¹ï¸  ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•˜ì„¸ìš”.\")\n",
    "    print(\"     â†’ ë‹¤ìŒ ì…€ ì‹¤í–‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 í¬íŠ¸ í¬ì›Œë”© ë°©ì‹ ì¶”ë¡  í…ŒìŠ¤íŠ¸ (ë¡œì»¬ í™˜ê²½)\n",
    "\n",
    "âš ï¸ ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ì•„ë˜ ëª…ë ¹ì–´ë¥¼ **í„°ë¯¸ë„ì—ì„œ ë³„ë„ë¡œ ì‹¤í–‰**í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "```bash\n",
    "# í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰ (ì´ ì…€ì—ì„œ ì‹¤í–‰í•˜ì§€ ë§ˆì„¸ìš”!)\n",
    "kubectl port-forward -n kubeflow-user01 svc/california-model-predictor 8081:80\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 4.3: í¬íŠ¸ í¬ì›Œë”© ë°©ì‹ ì¶”ë¡  í…ŒìŠ¤íŠ¸ (ë¡œì»¬ í™˜ê²½)\n",
    "# ======================================================================\n",
    "\n",
    "def test_inference_portforward(model_name, test_data, port=8081):\n",
    "    \"\"\"\n",
    "    í¬íŠ¸ í¬ì›Œë”©ì„ í†µí•´ ì¶”ë¡  í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì‹œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ê¸°ì¡´ test_inference.shë¥¼ ëŒ€ì²´í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ì‚¬ì „ ìš”êµ¬ì‚¬í•­:\n",
    "    í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ ì‹¤í–‰:\n",
    "    kubectl port-forward -n kubeflow-user01 svc/california-model-predictor 8081:80\n",
    "    \"\"\"\n",
    "    url = f\"http://localhost:{port}/v1/models/{model_name}:predict\"\n",
    "    \n",
    "    print(f\"  ğŸŒ ì¶”ë¡  URL: {url}\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            json=test_data,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"  âœ… ì¶”ë¡  ì„±ê³µ!\")\n",
    "            print()\n",
    "            print(f\"  ğŸ“Š ê²°ê³¼:\")\n",
    "            predictions = result.get(\"predictions\", [])\n",
    "            for i, pred in enumerate(predictions):\n",
    "                print(f\"    ìƒ˜í”Œ {i+1}: ${pred*100000:,.0f} (ì˜ˆì¸¡ ì£¼íƒ ê°€ê²©)\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"  âŒ ì¶”ë¡  ì‹¤íŒ¨: HTTP {response.status_code}\")\n",
    "            print(f\"     {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"  âŒ ì—°ê²° ì‹¤íŒ¨!\")\n",
    "        print()\n",
    "        print(f\"  ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "        print(f\"     í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”:\")\n",
    "        print(f\"     kubectl port-forward -n {NAMESPACE} svc/{MODEL_NAME}-predictor {port}:80\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  í¬íŠ¸ í¬ì›Œë”© ë°©ì‹ ì¶”ë¡  í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if env_type == \"local\":\n",
    "    result = test_inference_portforward(MODEL_NAME, test_data, port=8081)\n",
    "else:\n",
    "    print(\"  â„¹ï¸  Kubeflow í™˜ê²½ì—ì„œëŠ” ì´ì „ ì…€ì˜ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ì •ë¦¬ (ì„ íƒì‚¬í•­)\n",
    "\n",
    "ì‹¤ìŠµ í›„ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#  Step 5: ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ì„ íƒì‚¬í•­)\n",
    "# ======================================================================\n",
    "\n",
    "def cleanup_resources(model_name, namespace, delete_credentials=False):\n",
    "    \"\"\"\n",
    "    ì‹¤ìŠµ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(\"  ğŸ—‘ï¸  ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...\")\n",
    "    \n",
    "    # InferenceService ì‚­ì œ\n",
    "    try:\n",
    "        custom_api.delete_namespaced_custom_object(\n",
    "            group=\"serving.kserve.io\",\n",
    "            version=\"v1beta1\",\n",
    "            namespace=namespace,\n",
    "            plural=\"inferenceservices\",\n",
    "            name=model_name\n",
    "        )\n",
    "        print(f\"  âœ… InferenceService '{model_name}' ì‚­ì œ\")\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            print(f\"  â„¹ï¸  InferenceService '{model_name}' ì´ë¯¸ ì—†ìŒ\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸  InferenceService ì‚­ì œ ì‹¤íŒ¨: {e.reason}\")\n",
    "    \n",
    "    if delete_credentials:\n",
    "        # Secret ì‚­ì œ\n",
    "        try:\n",
    "            core_v1.delete_namespaced_secret(\"aws-s3-credentials\", namespace)\n",
    "            print(f\"  âœ… Secret 'aws-s3-credentials' ì‚­ì œ\")\n",
    "        except ApiException:\n",
    "            pass\n",
    "        \n",
    "        # ConfigMap ì‚­ì œ\n",
    "        try:\n",
    "            core_v1.delete_namespaced_config_map(\"s3-config\", namespace)\n",
    "            print(f\"  âœ… ConfigMap 's3-config' ì‚­ì œ\")\n",
    "        except ApiException:\n",
    "            pass\n",
    "    \n",
    "    print(\"  âœ… ì •ë¦¬ ì™„ë£Œ!\")\n",
    "\n",
    "# âš ï¸ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ë©´ ë¦¬ì†ŒìŠ¤ê°€ ì‚­ì œë©ë‹ˆë‹¤!\n",
    "# print(\"=\"*60)\n",
    "# print(\"  ë¦¬ì†ŒìŠ¤ ì •ë¦¬\")\n",
    "# print(\"=\"*60)\n",
    "# cleanup_resources(MODEL_NAME, NAMESPACE, delete_credentials=False)\n",
    "\n",
    "print(\"ğŸ’¡ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ê°€ í•„ìš”í•˜ë©´ ìœ„ ì…€ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… ì‹¤ìŠµ ì™„ë£Œ!\n",
    "\n",
    "### í•™ìŠµí•œ ë‚´ìš©\n",
    "\n",
    "- âœ… Kubernetes Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ Secret/ConfigMap ìƒì„±\n",
    "- âœ… KServe InferenceService ë°°í¬\n",
    "- âœ… ë°°í¬ ìƒíƒœ ëª¨ë‹ˆí„°ë§\n",
    "- âœ… REST APIë¥¼ í†µí•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸\n",
    "\n",
    "### ğŸ“š ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. **Lab 3-1**: Prometheus/Grafana ëª¨ë‹ˆí„°ë§\n",
    "2. **Lab 3-2**: CI/CD íŒŒì´í”„ë¼ì¸ í†µí•©\n",
    "3. **Project**: E2E MLOps íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "\n",
    "---\n",
    "\n",
    "Â© 2025 í˜„ëŒ€ì˜¤í† ì—ë²„ MLOps Training - Lab 2-3  \n",
    "**Environment**: Kubeflow Jupyter Notebook  \n",
    "**Model Serving**: KServe InferenceService"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
