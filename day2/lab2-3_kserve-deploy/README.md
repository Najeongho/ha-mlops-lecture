# Lab 2-3: KServe ë°°í¬

## ğŸ“‹ ê°œìš”

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì†Œìš”ì‹œê°„** | 40ë¶„ |
| **ë‚œì´ë„** | â­â­â­ |
| **ëª©í‘œ** | KServe InferenceServiceë¡œ ëª¨ë¸ ë°°í¬ ë° Canary ì „ëµ ì ìš© |

## ğŸ¯ í•™ìŠµ ëª©í‘œ

- KServe InferenceService ìƒì„±
- Sklearn ëª¨ë¸ ë°°í¬
- Canary ë°°í¬ ì „ëµ ì ìš©
- íŠ¸ë˜í”½ ë¶„í•  ë° ë¡¤ë°±

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         KServe InferenceService         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  Client  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”‚         Knative Serving             â”‚â”‚
â”‚  (curl)  â”‚        â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”‚  â”‚ Default   â”‚    â”‚  Canary   â”‚    â”‚â”‚
                    â”‚  â”‚  â”‚   (90%)   â”‚    â”‚   (10%)   â”‚    â”‚â”‚
                    â”‚  â”‚  â”‚ sklearn   â”‚    â”‚ sklearn   â”‚    â”‚â”‚
                    â”‚  â”‚  â”‚   v1      â”‚    â”‚   v2      â”‚    â”‚â”‚
                    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
lab2-3_kserve-deploy/
â”œâ”€â”€ README.md
â”œâ”€â”€ inference-service.yaml         # ê¸°ë³¸ InferenceService
â”œâ”€â”€ inference-service-canary.yaml  # Canary ë°°í¬
â”œâ”€â”€ test_inference.sh              # API í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ deploy.sh                      # ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
```

## ğŸ”§ ì‹¤ìŠµ ë‹¨ê³„

### Step 1: ëª¨ë¸ S3 ì—…ë¡œë“œ (ì´ë¯¸ ì™„ë£Œëœ ê²½ìš° ìƒëµ)

```bash
# MLflowì—ì„œ ëª¨ë¸ì„ S3ë¡œ ë³µì‚¬
aws s3 cp --recursive \
    s3://mlflow-artifacts/[run-id]/artifacts/model \
    s3://mlops-training-models/california/
```

### Step 2: InferenceService ìƒì„±

```bash
# YAML íŒŒì¼ ìˆ˜ì • (namespace, storageUri)
vim inference-service.yaml

# ë°°í¬
kubectl apply -f inference-service.yaml

# ìƒíƒœ í™•ì¸
kubectl get isvc california-model -n kubeflow-userXX
```

### Step 3: READY ìƒíƒœ ëŒ€ê¸°

```bash
# ìƒíƒœ ëª¨ë‹ˆí„°ë§ (READY=Trueê¹Œì§€)
kubectl get isvc california-model -n kubeflow-userXX -w

# ìƒì„¸ ì •ë³´ í™•ì¸
kubectl describe isvc california-model -n kubeflow-userXX
```

### Step 4: API í…ŒìŠ¤íŠ¸

```bash
# í¬íŠ¸ í¬ì›Œë”©
kubectl port-forward svc/california-model-predictor-default \
    -n kubeflow-userXX 8080:80

# í…ŒìŠ¤íŠ¸
./test_inference.sh
```

### Step 5: Canary ë°°í¬ (ì„ íƒ)

```bash
# Canary ë°°í¬ ì ìš©
kubectl apply -f inference-service-canary.yaml

# íŠ¸ë˜í”½ ë¶„ë°° í™•ì¸
kubectl get isvc california-model -n kubeflow-userXX
```

## âœ… ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] InferenceService YAML ì‘ì„±
- [ ] kubectl apply ì„±ê³µ
- [ ] READY=True ìƒíƒœ í™•ì¸
- [ ] /predict ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] (ì„ íƒ) Canary ë°°í¬ ì ìš©

## ğŸ“Š API ëª…ì„¸

### POST /v1/models/california-model:predict

**Request:**
```json
{
  "instances": [
    [8.3252, 41.0, 6.984, 1.024, 322.0, 2.556, 37.88, -122.23]
  ]
}
```

**Response:**
```json
{
  "predictions": [4.526]
}
```

## â“ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ: READY=False ì§€ì†

```bash
# Pod ìƒíƒœ í™•ì¸
kubectl get pods -n kubeflow-userXX | grep california

# ì´ë²¤íŠ¸ í™•ì¸
kubectl describe isvc california-model -n kubeflow-userXX
```

### ë¬¸ì œ: storageUri ì ‘ê·¼ ì‹¤íŒ¨

```bash
# S3 ë²„í‚· ê¶Œí•œ í™•ì¸
aws s3 ls s3://mlops-training-models/california/

# ServiceAccount IAM ì—­í•  í™•ì¸
kubectl describe sa default -n kubeflow-userXX
```

### ë¬¸ì œ: "502 Bad Gateway"

```bash
# Predictor Pod ë¡œê·¸ í™•ì¸
kubectl logs -l serving.kserve.io/inferenceservice=california-model \
    -n kubeflow-userXX
```

## ğŸ“š ì°¸ê³  ìë£Œ

- [KServe ê³µì‹ ë¬¸ì„œ](https://kserve.github.io/website/)
- [InferenceService API](https://kserve.github.io/website/0.10/reference/api/)
