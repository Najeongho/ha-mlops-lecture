#!/bin/bash
# ============================================================
# Lab 2-3: KServe InferenceService ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
# ============================================================
set -e

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

echo "============================================================"
echo "  KServe InferenceService ë°°í¬"
echo "============================================================"

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì„¤ì •
if [ -f "/var/run/secrets/kubernetes.io/serviceaccount/namespace" ]; then
    NAMESPACE=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)
elif [ -n "$USER_NAMESPACE" ]; then
    NAMESPACE="$USER_NAMESPACE"
else
    NAMESPACE="kubeflow-user-example-com"
    echo -e "${YELLOW}âš ï¸  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”: $NAMESPACE${NC}"
fi

# ëª¨ë¸ ì„¤ì •
MODEL_NAME=${MODEL_NAME:-"california-model"}
S3_BUCKET=${S3_BUCKET:-"mlops-training-user01"}

echo "ğŸ“ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: $NAMESPACE"
echo "ğŸ¤– ëª¨ë¸ëª…: $MODEL_NAME"
echo ""

# Storage URI í™•ì¸
if [ -z "$STORAGE_URI" ]; then
    echo -e "${YELLOW}âš ï¸  STORAGE_URIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.${NC}"
    echo ""
    echo "S3ì—ì„œ ëª¨ë¸ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”:"
    echo "  aws s3 ls s3://$S3_BUCKET/mlflow-artifacts/ --recursive | grep MLmodel"
    echo ""
    echo "ê·¸ ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:"
    echo "  export STORAGE_URI='s3://$S3_BUCKET/mlflow-artifacts/EXPERIMENT_ID/RUN_ID/artifacts/model'"
    echo ""
    exit 1
fi

echo "ğŸ“¦ Storage URI: $STORAGE_URI"
echo ""

# ê¸°ì¡´ InferenceService ì‚­ì œ (ìˆìœ¼ë©´)
echo "ğŸ—‘ï¸  ê¸°ì¡´ InferenceService í™•ì¸ ì¤‘..."
if kubectl get inferenceservice $MODEL_NAME -n $NAMESPACE &>/dev/null; then
    echo "  ê¸°ì¡´ InferenceService ì‚­ì œ ì¤‘..."
    kubectl delete inferenceservice $MODEL_NAME -n $NAMESPACE --wait=true
    sleep 5
fi

# InferenceService YAML ìƒì„± ë° ì ìš©
echo ""
echo "ğŸ“ InferenceService ìƒì„± ì¤‘..."

cat <<EOF | kubectl apply -f -
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: $MODEL_NAME
  namespace: $NAMESPACE
  annotations:
    # âš ï¸ ì¤‘ìš”: Istio sidecar ë¹„í™œì„±í™” (RBAC 403 ì—ëŸ¬ ë°©ì§€)
    sidecar.istio.io/inject: "false"
spec:
  predictor:
    model:
      modelFormat:
        name: sklearn
      storageUri: "$STORAGE_URI"
      resources:
        requests:
          cpu: "500m"
          memory: "1Gi"
        limits:
          cpu: "1"
          memory: "2Gi"
EOF

echo -e "${GREEN}âœ… InferenceService ìƒì„± ì™„ë£Œ${NC}"
echo ""

# ë°°í¬ ëŒ€ê¸°
echo "â³ ë°°í¬ ëŒ€ê¸° ì¤‘ (ìµœëŒ€ 5ë¶„)..."
echo "   (ë³´í†µ 2-3ë¶„ ì†Œìš”)"
echo ""

TIMEOUT=300
START_TIME=$(date +%s)

while true; do
    CURRENT_TIME=$(date +%s)
    ELAPSED=$((CURRENT_TIME - START_TIME))
    
    if [ $ELAPSED -ge $TIMEOUT ]; then
        echo -e "${RED}âŒ íƒ€ì„ì•„ì›ƒ: ${TIMEOUT}ì´ˆ ì´ˆê³¼${NC}"
        echo ""
        echo "ìƒíƒœ í™•ì¸:"
        kubectl describe inferenceservice $MODEL_NAME -n $NAMESPACE | tail -30
        exit 1
    fi
    
    # ìƒíƒœ í™•ì¸
    READY=$(kubectl get inferenceservice $MODEL_NAME -n $NAMESPACE -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
    REASON=$(kubectl get inferenceservice $MODEL_NAME -n $NAMESPACE -o jsonpath='{.status.conditions[?(@.type=="Ready")].reason}' 2>/dev/null || echo "Pending")
    
    if [ "$READY" == "True" ]; then
        echo ""
        echo -e "${GREEN}âœ… InferenceService Ready! (${ELAPSED}ì´ˆ ì†Œìš”)${NC}"
        break
    elif [ "$READY" == "False" ]; then
        echo -e "${RED}âŒ ë°°í¬ ì‹¤íŒ¨: $REASON${NC}"
        echo ""
        echo "ë¡œê·¸ í™•ì¸:"
        kubectl logs -n $NAMESPACE -l serving.knative.dev/configuration=${MODEL_NAME}-predictor -c storage-initializer --tail=20 2>/dev/null || echo "ë¡œê·¸ ì—†ìŒ"
        exit 1
    else
        printf "  â³ Status: %s | Reason: %s (%ds)\r" "$READY" "$REASON" "$ELAPSED"
    fi
    
    sleep 10
done

# ìµœì¢… ìƒíƒœ ì¶œë ¥
echo ""
echo "============================================================"
echo "  ë°°í¬ ì™„ë£Œ"
echo "============================================================"
echo ""
kubectl get inferenceservice $MODEL_NAME -n $NAMESPACE
echo ""

# Pod ìƒíƒœ
echo "ğŸ“‹ Pod ìƒíƒœ:"
kubectl get pods -n $NAMESPACE -l serving.knative.dev/configuration=${MODEL_NAME}-predictor
echo ""

# ë‚´ë¶€ URL
echo "ğŸ”— í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ URL:"
echo "   http://${MODEL_NAME}-predictor.${NAMESPACE}.svc.cluster.local/v1/models/${MODEL_NAME}:predict"
echo ""
echo -e "${GREEN}âœ… ë°°í¬ ì™„ë£Œ! test_inference.shë¡œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.${NC}"
