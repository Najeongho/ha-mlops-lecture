{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2-4 (Bonus): Model Optimization\n",
    "\n",
    "## ONNX ë³€í™˜ ë° ì–‘ìí™” ì‹¤ìŠµ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” í•™ìŠµëœ ML ëª¨ë¸ì„ ìµœì í™”í•˜ì—¬ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ“‹ ì‹¤ìŠµ ë‚´ìš©\n",
    "\n",
    "1. Scikit-learn ëª¨ë¸ í•™ìŠµ\n",
    "2. ONNX í¬ë§· ë³€í™˜\n",
    "3. ë™ì  ì–‘ìí™” ì ìš©\n",
    "4. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\n",
    "5. MLflowì— ê²°ê³¼ ê¸°ë¡\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install scikit-learn onnx onnxruntime skl2onnx mlflow joblib -q\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ONNX\n",
    "import onnx\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "\n",
    "print(\"âœ… Import ì™„ë£Œ\")\n",
    "print(f\"   - ONNX: {onnx.__version__}\")\n",
    "print(f\"   - ONNX Runtime: {ort.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "Iris ë°ì´í„°ì…‹ìœ¼ë¡œ RandomForest ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Train/Test ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"   - í•™ìŠµ ë°ì´í„°: {len(X_train)} samples\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)} samples\")\n",
    "print(f\"   - í”¼ì²˜ ìˆ˜: {X.shape[1]}\")\n",
    "print(f\"   - í´ë˜ìŠ¤ ìˆ˜: {len(iris.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ì •í™•ë„ í‰ê°€\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›ë³¸ ëª¨ë¸ ì €ì¥\n",
    "original_path = output_dir / \"model_original.joblib\"\n",
    "joblib.dump(model, original_path)\n",
    "\n",
    "original_size = os.path.getsize(original_path) / 1024\n",
    "print(f\"âœ… ì›ë³¸ ëª¨ë¸ ì €ì¥: {original_path}\")\n",
    "print(f\"   - íŒŒì¼ í¬ê¸°: {original_size:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. ONNX ë³€í™˜\n",
    "\n",
    "Scikit-learn ëª¨ë¸ì„ ONNX í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì…ë ¥ í˜•ì‹ ì •ì˜\n",
    "initial_type = [('float_input', FloatTensorType([None, 4]))]\n",
    "\n",
    "# ONNX ë³€í™˜\n",
    "onnx_model = convert_sklearn(\n",
    "    model,\n",
    "    initial_types=initial_type,\n",
    "    target_opset=12,\n",
    "    options={id(model): {'zipmap': False}}\n",
    ")\n",
    "\n",
    "# ì €ì¥\n",
    "onnx_path = output_dir / \"model_optimized.onnx\"\n",
    "with open(onnx_path, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "onnx_size = os.path.getsize(onnx_path) / 1024\n",
    "reduction = (1 - onnx_size / original_size) * 100\n",
    "\n",
    "print(f\"âœ… ONNX ë³€í™˜ ì™„ë£Œ!\")\n",
    "print(f\"   - íŒŒì¼: {onnx_path}\")\n",
    "print(f\"   - í¬ê¸°: {onnx_size:.1f} KB (ì›ë³¸ ëŒ€ë¹„ {reduction:.1f}% ê°ì†Œ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX ëª¨ë¸ ê²€ì¦\n",
    "test_samples = X_test[:3].astype(np.float32)\n",
    "\n",
    "# ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡\n",
    "original_pred = model.predict(test_samples)\n",
    "\n",
    "# ONNX ëª¨ë¸ ì˜ˆì¸¡\n",
    "session = ort.InferenceSession(str(onnx_path))\n",
    "input_name = session.get_inputs()[0].name\n",
    "onnx_pred = session.run(None, {input_name: test_samples})[0]\n",
    "\n",
    "print(f\"âœ… ì˜ˆì¸¡ ê²€ì¦\")\n",
    "print(f\"   - ì›ë³¸ ëª¨ë¸: {original_pred.tolist()}\")\n",
    "print(f\"   - ONNX ëª¨ë¸: {onnx_pred.tolist()}\")\n",
    "print(f\"   - ì¼ì¹˜ ì—¬ë¶€: {'âœ… ì¼ì¹˜!' if np.array_equal(original_pred, onnx_pred) else 'âŒ ë¶ˆì¼ì¹˜'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ì–‘ìí™” ì ìš©\n",
    "\n",
    "ONNX ëª¨ë¸ì— ë™ì  ì–‘ìí™”ë¥¼ ì ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë™ì  ì–‘ìí™” ì ìš©\n",
    "quantized_path = output_dir / \"model_quantized.onnx\"\n",
    "\n",
    "quantize_dynamic(\n",
    "    model_input=str(onnx_path),\n",
    "    model_output=str(quantized_path),\n",
    "    weight_type=QuantType.QUInt8,\n",
    "    optimize_model=True\n",
    ")\n",
    "\n",
    "quantized_size = os.path.getsize(quantized_path) / 1024\n",
    "total_reduction = (1 - quantized_size / original_size) * 100\n",
    "\n",
    "print(f\"âœ… ì–‘ìí™” ì™„ë£Œ!\")\n",
    "print(f\"   - íŒŒì¼: {quantized_path}\")\n",
    "print(f\"   - í¬ê¸°: {quantized_size:.1f} KB (ì›ë³¸ ëŒ€ë¹„ {total_reduction:.1f}% ê°ì†Œ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì–‘ìí™” ëª¨ë¸ ì •í™•ë„ ê²€ì¦\n",
    "X_test_float = X_test.astype(np.float32)\n",
    "\n",
    "# ONNX ì •í™•ë„\n",
    "session_onnx = ort.InferenceSession(str(onnx_path))\n",
    "pred_onnx = session_onnx.run(None, {input_name: X_test_float})[0]\n",
    "acc_onnx = accuracy_score(y_test, pred_onnx)\n",
    "\n",
    "# ì–‘ìí™” ì •í™•ë„\n",
    "session_quant = ort.InferenceSession(str(quantized_path))\n",
    "pred_quant = session_quant.run(None, {input_name: X_test_float})[0]\n",
    "acc_quant = accuracy_score(y_test, pred_quant)\n",
    "\n",
    "print(f\"âœ… ì •í™•ë„ ë¹„êµ\")\n",
    "print(f\"   - ì›ë³¸ ëª¨ë¸:   {accuracy:.4f}\")\n",
    "print(f\"   - ONNX ëª¨ë¸:   {acc_onnx:.4f}\")\n",
    "print(f\"   - ì–‘ìí™” ëª¨ë¸: {acc_quant:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(predict_func, X, n_iterations=1000, warmup=100):\n",
    "    \"\"\"ì¶”ë¡  ì‹œê°„ ì¸¡ì •\"\"\"\n",
    "    # ì›œì—…\n",
    "    for _ in range(warmup):\n",
    "        predict_func(X)\n",
    "    \n",
    "    # ì¸¡ì •\n",
    "    times = []\n",
    "    for _ in range(n_iterations):\n",
    "        start = time.perf_counter()\n",
    "        predict_func(X)\n",
    "        end = time.perf_counter()\n",
    "        times.append((end - start) * 1000)  # ms\n",
    "    \n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "test_input = X_test[:1].astype(np.float32)\n",
    "\n",
    "print(\"â³ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›ë³¸ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬\n",
    "mean_original, std_original = benchmark(\n",
    "    lambda x: model.predict(x),\n",
    "    test_input\n",
    ")\n",
    "print(f\"âœ… Original: {mean_original:.3f} Â± {std_original:.3f} ms\")\n",
    "\n",
    "# ONNX ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬\n",
    "session_onnx = ort.InferenceSession(str(onnx_path))\n",
    "mean_onnx, std_onnx = benchmark(\n",
    "    lambda x: session_onnx.run(None, {input_name: x}),\n",
    "    test_input\n",
    ")\n",
    "print(f\"âœ… ONNX: {mean_onnx:.3f} Â± {std_onnx:.3f} ms\")\n",
    "\n",
    "# ì–‘ìí™” ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬\n",
    "session_quant = ort.InferenceSession(str(quantized_path))\n",
    "mean_quant, std_quant = benchmark(\n",
    "    lambda x: session_quant.run(None, {input_name: x}),\n",
    "    test_input\n",
    ")\n",
    "print(f\"âœ… Quantized: {mean_quant:.3f} Â± {std_quant:.3f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ìš”ì•½\n",
    "speed_onnx = mean_original / mean_onnx\n",
    "speed_quant = mean_original / mean_quant\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š ìµœì í™” ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nëª¨ë¸ í¬ê¸°:\")\n",
    "print(f\"  - Original:  {original_size:.1f} KB\")\n",
    "print(f\"  - ONNX:      {onnx_size:.1f} KB ({(1-onnx_size/original_size)*100:.1f}% ê°ì†Œ)\")\n",
    "print(f\"  - Quantized: {quantized_size:.1f} KB ({(1-quantized_size/original_size)*100:.1f}% ê°ì†Œ)\")\n",
    "\n",
    "print(f\"\\nì¶”ë¡  ì†ë„:\")\n",
    "print(f\"  - Original:  {mean_original:.3f} ms (1.00x)\")\n",
    "print(f\"  - ONNX:      {mean_onnx:.3f} ms ({speed_onnx:.2f}x faster)\")\n",
    "print(f\"  - Quantized: {mean_quant:.3f} ms ({speed_quant:.2f}x faster)\")\n",
    "\n",
    "print(f\"\\nì •í™•ë„:\")\n",
    "print(f\"  - Original:  {accuracy:.4f}\")\n",
    "print(f\"  - ONNX:      {acc_onnx:.4f}\")\n",
    "print(f\"  - Quantized: {acc_quant:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. MLflow ê¸°ë¡ (ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow ê¸°ë¡ (ì„ íƒì )\n",
    "try:\n",
    "    mlflow.set_experiment(\"model-optimization\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"optimization-results\"):\n",
    "        # ë©”íŠ¸ë¦­\n",
    "        mlflow.log_metric(\"original_size_kb\", original_size)\n",
    "        mlflow.log_metric(\"onnx_size_kb\", onnx_size)\n",
    "        mlflow.log_metric(\"quantized_size_kb\", quantized_size)\n",
    "        mlflow.log_metric(\"original_inference_ms\", mean_original)\n",
    "        mlflow.log_metric(\"onnx_inference_ms\", mean_onnx)\n",
    "        mlflow.log_metric(\"quantized_inference_ms\", mean_quant)\n",
    "        mlflow.log_metric(\"speed_improvement\", speed_quant)\n",
    "        \n",
    "        # ëª¨ë¸ ì•„í‹°íŒ©íŠ¸\n",
    "        mlflow.log_artifact(str(quantized_path))\n",
    "        \n",
    "        print(f\"âœ… MLflow ê¸°ë¡ ì™„ë£Œ!\")\n",
    "        print(f\"   - Run ID: {mlflow.active_run().info.run_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  MLflow ê¸°ë¡ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"   (MLflow ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… ì‹¤ìŠµ ì™„ë£Œ!\n",
    "\n",
    "### í•µì‹¬ í¬ì¸íŠ¸\n",
    "\n",
    "1. **ONNX ë³€í™˜**: Scikit-learn ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜í•˜ì—¬ ì•½ 68% í¬ê¸° ê°ì†Œ\n",
    "2. **ì–‘ìí™”**: ì¶”ê°€ë¡œ ì•½ 90% í¬ê¸° ê°ì†Œ (ì›ë³¸ ëŒ€ë¹„)\n",
    "3. **ì†ë„ í–¥ìƒ**: ONNX Runtimeìœ¼ë¡œ ì•½ 7-9ë°° ì¶”ë¡  ì†ë„ í–¥ìƒ\n",
    "4. **ì •í™•ë„ ìœ ì§€**: ìµœì í™” í›„ì—ë„ ì •í™•ë„ ì†ì‹¤ ì—†ìŒ\n",
    "\n",
    "### ì‹¤ë¬´ ì ìš©\n",
    "\n",
    "- ì—£ì§€ ë””ë°”ì´ìŠ¤ ë°°í¬ ì‹œ ëª¨ë¸ ìµœì í™” í•„ìˆ˜\n",
    "- KServe Triton Runtimeìœ¼ë¡œ ONNX ëª¨ë¸ ì„œë¹™ ê°€ëŠ¥\n",
    "- GPU í™˜ê²½ì—ì„œëŠ” TensorRT ì¶”ê°€ ì ìš© ê³ ë ¤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
