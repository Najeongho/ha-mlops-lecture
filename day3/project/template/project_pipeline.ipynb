{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ Day 3 í”„ë¡œì íŠ¸: MLOps íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "\n",
    "## í”„ë¡œì íŠ¸ ê°œìš”\n",
    "\n",
    "ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ì™„ì „í•œ MLOps íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ìš”êµ¬ì‚¬í•­\n",
    "\n",
    "1. **ë°ì´í„° íŒŒì´í”„ë¼ì¸**: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "2. **ì‹¤í—˜ ì¶”ì **: MLflowë¥¼ ì‚¬ìš©í•œ ì‹¤í—˜ ê´€ë¦¬\n",
    "3. **ëª¨ë¸ í•™ìŠµ**: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í¬í•¨\n",
    "4. **ëª¨ë¸ í‰ê°€**: ì„±ëŠ¥ ê¸°ì¤€ì— ë”°ë¥¸ ë°°í¬ ê²°ì •\n",
    "5. **ëª¨ë¸ ë°°í¬**: KServeë¥¼ ì‚¬ìš©í•œ ìë™ ë°°í¬\n",
    "6. **ëª¨ë‹ˆí„°ë§**: ë°°í¬ëœ ëª¨ë¸ ìƒíƒœ í™•ì¸\n",
    "\n",
    "### íŒŒì´í”„ë¼ì¸ êµ¬ì¡°\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  load_data  â”‚â”€â”€â–¶â”‚  preprocess â”‚â”€â”€â–¶â”‚ hyperparameter  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    search       â”‚\n",
    "                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                             â”‚\n",
    "                                             â–¼\n",
    "                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                    â”‚   train_best    â”‚\n",
    "                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                             â”‚\n",
    "                                             â–¼\n",
    "                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                    â”‚    evaluate     â”‚\n",
    "                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                             â”‚\n",
    "                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                              â–¼                             â–¼\n",
    "                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                       â”‚   deploy    â”‚               â”‚    alert    â”‚\n",
    "                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install kfp==1.8.22 mlflow==2.9.2 scikit-learn pandas numpy -q\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import create_component_from_func\n",
    "from kfp import compiler\n",
    "import os\n",
    "\n",
    "print(f\"KFP Version: {kfp.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ë³¸ì¸ì˜ ì„¤ì •ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”!)\n",
    "TEAM_NAME = \"team-XX\"  # TODO: íŒ€ ì´ë¦„ìœ¼ë¡œ ë³€ê²½\n",
    "USER_NAMESPACE = os.getenv('NAMESPACE', 'kubeflow-user01')  # TODO: ë³¸ì¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ë³€ê²½\n",
    "\n",
    "MLFLOW_TRACKING_URI = os.getenv(\n",
    "    'MLFLOW_TRACKING_URI',\n",
    "    'http://mlflow-server-service.mlflow-system.svc.cluster.local:5000'\n",
    ")\n",
    "\n",
    "print(f\"Team: {TEAM_NAME}\")\n",
    "print(f\"Namespace: {USER_NAMESPACE}\")\n",
    "print(f\"MLflow URI: {MLFLOW_TRACKING_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ì»´í¬ë„ŒíŠ¸ êµ¬í˜„\n",
    "\n",
    "### 2.1 ë°ì´í„° ë¡œë“œ ì»´í¬ë„ŒíŠ¸\n",
    "\n",
    "**TODO**: ë°ì´í„° ë¡œë“œ ì»´í¬ë„ŒíŠ¸ë¥¼ ì™„ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def load_data(dataset_name: str = \"california\") -> str:\n",
    "    \"\"\"\n",
    "    ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    TODO:\n",
    "    1. sklearnì—ì„œ California Housing ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    2. DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    3. CSVë¡œ ì €ì¥\n",
    "    4. ì €ì¥ ê²½ë¡œ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    # TODO: sklearnì—ì„œ ë°ì´í„° ë¡œë“œ\n",
    "    # from sklearn.datasets import ...\n",
    "    \n",
    "    output_path = \"/tmp/raw_data.csv\"\n",
    "    \n",
    "    # TODO: ë°ì´í„° ì €ì¥\n",
    "    # df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ì „ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸\n",
    "\n",
    "**TODO**: ì „ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ì™„ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def preprocess(data_path: str, test_size: float = 0.2) -> str:\n",
    "    \"\"\"\n",
    "    ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    TODO:\n",
    "    1. CSV ë¡œë“œ\n",
    "    2. Train/Test ë¶„í• \n",
    "    3. StandardScalerë¡œ ì •ê·œí™”\n",
    "    4. numpy ë°°ì—´ë¡œ ì €ì¥\n",
    "    5. ì €ì¥ ë””ë ‰í† ë¦¬ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import os\n",
    "    \n",
    "    output_dir = \"/tmp/processed\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # TODO: ì „ì²˜ë¦¬ ë¡œì§ êµ¬í˜„\n",
    "    \n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ì»´í¬ë„ŒíŠ¸ (ì„ íƒ)\n",
    "\n",
    "**TODO**: ì—¬ëŸ¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ë¥¼ êµ¬í˜„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def hyperparameter_search(\n",
    "    data_dir: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    experiment_name: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    TODO:\n",
    "    1. ì—¬ëŸ¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ì •ì˜\n",
    "    2. ê° ì¡°í•©ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "    3. MLflowì— ëª¨ë“  ì‹¤í—˜ ê¸°ë¡\n",
    "    4. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    import json\n",
    "    \n",
    "    # TODO: í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ êµ¬í˜„\n",
    "    # íŒíŠ¸: n_estimators: [50, 100, 200], max_depth: [5, 10, 15]\n",
    "    \n",
    "    best_params = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 10\n",
    "    }\n",
    "    \n",
    "    return json.dumps(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ëª¨ë¸ í•™ìŠµ ì»´í¬ë„ŒíŠ¸\n",
    "\n",
    "**TODO**: MLflow ì—°ë™ëœ ëª¨ë¸ í•™ìŠµ ì»´í¬ë„ŒíŠ¸ë¥¼ ì™„ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def train_model(\n",
    "    data_dir: str,\n",
    "    best_params: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    experiment_name: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    TODO:\n",
    "    1. ë°ì´í„° ë¡œë“œ\n",
    "    2. MLflow ì„¤ì •\n",
    "    3. íŒŒë¼ë¯¸í„° ë¡œê¹…\n",
    "    4. ëª¨ë¸ í•™ìŠµ\n",
    "    5. ë©”íŠ¸ë¦­ ë¡œê¹… (MSE, RMSE, R2)\n",
    "    6. ëª¨ë¸ ì €ì¥\n",
    "    7. Run ID ë°˜í™˜\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import numpy as np\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    import os\n",
    "    \n",
    "    os.environ['MLFLOW_TRACKING_URI'] = mlflow_tracking_uri\n",
    "    \n",
    "    # TODO: ëª¨ë¸ í•™ìŠµ ë° MLflow ë¡œê¹… êµ¬í˜„\n",
    "    \n",
    "    run_id = \"placeholder\"\n",
    "    return run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ëª¨ë¸ í‰ê°€ ì»´í¬ë„ŒíŠ¸\n",
    "\n",
    "**TODO**: ë°°í¬ ê²°ì •ì„ ë‚´ë¦¬ëŠ” í‰ê°€ ì»´í¬ë„ŒíŠ¸ë¥¼ ì™„ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def evaluate_model(\n",
    "    run_id: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    r2_threshold: float = 0.8\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ë°°í¬ ê²°ì •ì„ ë‚´ë¦½ë‹ˆë‹¤.\n",
    "    \n",
    "    TODO:\n",
    "    1. MLflowì—ì„œ Run ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "    2. R2 ë©”íŠ¸ë¦­ í™•ì¸\n",
    "    3. ì„ê³„ê°’ê³¼ ë¹„êµ\n",
    "    4. \"deploy\" ë˜ëŠ” \"skip\" ë°˜í™˜\n",
    "    \"\"\"\n",
    "    import mlflow\n",
    "    import os\n",
    "    \n",
    "    os.environ['MLFLOW_TRACKING_URI'] = mlflow_tracking_uri\n",
    "    \n",
    "    # TODO: í‰ê°€ ë¡œì§ êµ¬í˜„\n",
    "    \n",
    "    decision = \"deploy\"  # or \"skip\"\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 ë°°í¬/ì•Œë¦¼ ì»´í¬ë„ŒíŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def deploy_model(run_id: str, model_name: str, namespace: str, mlflow_tracking_uri: str):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ì„ KServeë¡œ ë°°í¬í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    íŒíŠ¸: Kubernetes Python í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    print(f\"Deploying model: {model_name}\")\n",
    "    print(f\"Namespace: {namespace}\")\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    # TODO: KServe InferenceService ìƒì„±\n",
    "\n",
    "\n",
    "@create_component_from_func\n",
    "def send_alert(run_id: str, message: str = \"Model did not meet threshold\"):\n",
    "    \"\"\"ì„±ëŠ¥ ë¯¸ë‹¬ ì•Œë¦¼ì„ ë³´ëƒ…ë‹ˆë‹¤.\"\"\"\n",
    "    print(f\"âš ï¸ ALERT: {message}\")\n",
    "    print(f\"Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. íŒŒì´í”„ë¼ì¸ ì •ì˜\n",
    "\n",
    "**TODO**: ìœ„ì—ì„œ ì •ì˜í•œ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì—°ê²°í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ì™„ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=f'{TEAM_NAME}-mlops-pipeline',\n",
    "    description='MLOps Project Pipeline'\n",
    ")\n",
    "def project_pipeline(\n",
    "    dataset_name: str = \"california\",\n",
    "    mlflow_tracking_uri: str = \"http://mlflow-server-service.mlflow-system.svc.cluster.local:5000\",\n",
    "    experiment_name: str = \"project-experiment\",\n",
    "    model_name: str = \"project-model\",\n",
    "    namespace: str = \"kubeflow-user01\",\n",
    "    r2_threshold: float = 0.8\n",
    "):\n",
    "    \"\"\"\n",
    "    TODO: íŒŒì´í”„ë¼ì¸ êµ¬í˜„\n",
    "    \n",
    "    1. load_data í˜¸ì¶œ\n",
    "    2. preprocess í˜¸ì¶œ (load_data ì¶œë ¥ ì‚¬ìš©)\n",
    "    3. hyperparameter_search í˜¸ì¶œ (ì„ íƒ)\n",
    "    4. train_model í˜¸ì¶œ\n",
    "    5. evaluate_model í˜¸ì¶œ\n",
    "    6. dsl.Conditionìœ¼ë¡œ ì¡°ê±´ë¶€ ë°°í¬\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: ë°ì´í„° ë¡œë“œ\n",
    "    load_task = load_data(dataset_name=dataset_name)\n",
    "    \n",
    "    # Step 2: ì „ì²˜ë¦¬\n",
    "    # TODO: preprocess ì»´í¬ë„ŒíŠ¸ ì—°ê²°\n",
    "    \n",
    "    # Step 3: í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ (ì„ íƒ)\n",
    "    # TODO: hyperparameter_search ì»´í¬ë„ŒíŠ¸ ì—°ê²°\n",
    "    \n",
    "    # Step 4: ëª¨ë¸ í•™ìŠµ\n",
    "    # TODO: train_model ì»´í¬ë„ŒíŠ¸ ì—°ê²°\n",
    "    \n",
    "    # Step 5: ëª¨ë¸ í‰ê°€\n",
    "    # TODO: evaluate_model ì»´í¬ë„ŒíŠ¸ ì—°ê²°\n",
    "    \n",
    "    # Step 6: ì¡°ê±´ë¶€ ë°°í¬\n",
    "    # TODO: dsl.Condition ì‚¬ìš©í•˜ì—¬ ì¡°ê±´ë¶€ ë¶„ê¸° êµ¬í˜„\n",
    "    # with dsl.Condition(evaluate_task.output == \"deploy\"):\n",
    "    #     deploy_model(...)\n",
    "    # with dsl.Condition(evaluate_task.output == \"skip\"):\n",
    "    #     send_alert(...)\n",
    "    \n",
    "    pass  # TODO: ìœ„ì˜ TODOë“¤ì„ êµ¬í˜„í•œ í›„ ì´ ì¤„ ì‚­ì œ\n",
    "\n",
    "print(\"âœ… íŒŒì´í”„ë¼ì¸ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. íŒŒì´í”„ë¼ì¸ ì»´íŒŒì¼ ë° ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì»´íŒŒì¼\n",
    "pipeline_file = f'{TEAM_NAME}_pipeline.yaml'\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=project_pipeline,\n",
    "    package_path=pipeline_file\n",
    ")\n",
    "\n",
    "print(f\"âœ… Pipeline compiled: {pipeline_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤í–‰\n",
    "try:\n",
    "    client = kfp.Client()\n",
    "    print(f\"âœ… KFP Client connected\")\n",
    "    \n",
    "    run = client.create_run_from_pipeline_func(\n",
    "        project_pipeline,\n",
    "        arguments={\n",
    "            'dataset_name': 'california',\n",
    "            'experiment_name': f'{TEAM_NAME}-experiment',\n",
    "            'model_name': f'{TEAM_NAME}-model',\n",
    "            'namespace': USER_NAMESPACE,\n",
    "            'r2_threshold': 0.75\n",
    "        },\n",
    "        experiment_name=f'{TEAM_NAME}-project',\n",
    "        run_name=f'{TEAM_NAME}-run-001'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Pipeline submitted!\")\n",
    "    print(f\"   Run ID: {run.run_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not submit: {e}\")\n",
    "    print(\"\\nğŸ’¡ Upload YAML manually via Kubeflow UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "ë°œí‘œ ì „ í™•ì¸ì‚¬í•­:\n",
    "\n",
    "- [ ] íŒŒì´í”„ë¼ì¸ì´ ì˜¤ë¥˜ ì—†ì´ ì»´íŒŒì¼ë˜ëŠ”ê°€?\n",
    "- [ ] ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒ ì‹¤í–‰ë˜ëŠ”ê°€?\n",
    "- [ ] MLflowì— ì‹¤í—˜ì´ ê¸°ë¡ë˜ëŠ”ê°€?\n",
    "- [ ] ì¡°ê±´ë¶€ ë¶„ê¸°ê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ê°€?\n",
    "- [ ] ëª¨ë¸ ë°°í¬ê°€ ì„±ê³µí•˜ëŠ”ê°€?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ ë°œí‘œ ì¤€ë¹„\n",
    "\n",
    "### ë°œí‘œ ë‚´ìš© (15ë¶„)\n",
    "\n",
    "1. **íŒŒì´í”„ë¼ì¸ ê°œìš”** (2ë¶„)\n",
    "   - ì „ì²´ êµ¬ì¡° ì„¤ëª…\n",
    "   - ê° ì»´í¬ë„ŒíŠ¸ ì—­í• \n",
    "\n",
    "2. **êµ¬í˜„ í•˜ì´ë¼ì´íŠ¸** (5ë¶„)\n",
    "   - í•µì‹¬ ì½”ë“œ ì„¤ëª…\n",
    "   - ì–´ë ¤ì› ë˜ ë¶€ë¶„ê³¼ í•´ê²° ë°©ë²•\n",
    "\n",
    "3. **ë°ëª¨** (5ë¶„)\n",
    "   - íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "   - MLflow UI ê²°ê³¼ í™•ì¸\n",
    "   - ë°°í¬ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "4. **Q&A** (3ë¶„)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
