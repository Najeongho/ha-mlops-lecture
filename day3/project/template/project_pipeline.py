"""
ğŸ¯ ì¡°ë³„ í”„ë¡œì íŠ¸ í…œí”Œë¦¿: E2E ML Pipeline
=========================================

ì´ í…œí”Œë¦¿ì„ ìˆ˜ì •í•˜ì—¬ íŒ€ í”„ë¡œì íŠ¸ë¥¼ ì™„ì„±í•˜ì„¸ìš”.

TODO í‘œì‹œëœ ë¶€ë¶„ì„ êµ¬í˜„í•˜ì„¸ìš”!

ì‹¤í–‰:
    python project_pipeline.py
"""

import kfp
from kfp import dsl
from kfp.components import create_component_from_func
from kfp import compiler


# ============================================================
# TODO 1: ë°ì´í„° ë¡œë“œ ì»´í¬ë„ŒíŠ¸
# ============================================================

@create_component_from_func
def load_data() -> str:
    """
    California Housing ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Returns:
        ì €ì¥ëœ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    """
    # TODO: ì•„ë˜ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”
    
    from sklearn.datasets import fetch_california_housing
    import pandas as pd
    
    print("=" * 50)
    print("  Step 1: Load Data")
    print("=" * 50)
    
    # ë°ì´í„° ë¡œë“œ
    data = fetch_california_housing()
    df = pd.DataFrame(data.data, columns=data.feature_names)
    df['target'] = data.target
    
    # ì €ì¥
    output_path = "/tmp/data.csv"
    df.to_csv(output_path, index=False)
    
    print(f"  âœ… Loaded {len(df)} rows, {len(df.columns)} columns")
    
    return output_path


# ============================================================
# TODO 2: ì „ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸
# ============================================================

@create_component_from_func
def preprocess(data_path: str) -> str:
    """
    ë°ì´í„° ì „ì²˜ë¦¬ ë° Train/Test ë¶„í• 
    
    Args:
        data_path: ì…ë ¥ ë°ì´í„° ê²½ë¡œ
    
    Returns:
        ì „ì²˜ë¦¬ëœ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    # TODO: ì•„ë˜ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”
    
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    import os
    
    print("=" * 50)
    print("  Step 2: Preprocess")
    print("=" * 50)
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(data_path)
    
    # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
    X = df.drop('target', axis=1)
    y = df['target']
    
    # Train/Test ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # ì €ì¥
    output_dir = "/tmp/processed"
    os.makedirs(output_dir, exist_ok=True)
    
    # TODO: ë°ì´í„° ì €ì¥ êµ¬í˜„
    # íŒíŠ¸: np.save()ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
    np.save(f"{output_dir}/X_train.npy", X_train.values)
    np.save(f"{output_dir}/X_test.npy", X_test.values)
    np.save(f"{output_dir}/y_train.npy", y_train.values)
    np.save(f"{output_dir}/y_test.npy", y_test.values)
    
    print(f"  âœ… Train: {len(X_train)}, Test: {len(X_test)}")
    
    return output_dir


# ============================================================
# TODO 3: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì»´í¬ë„ŒíŠ¸
# ============================================================

@create_component_from_func
def feature_engineering(data_dir: str) -> str:
    """
    í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ - ìƒˆë¡œìš´ íŒŒìƒ í”¼ì²˜ ìƒì„±
    
    Args:
        data_dir: ì „ì²˜ë¦¬ëœ ë°ì´í„° ë””ë ‰í† ë¦¬
    
    Returns:
        í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œëœ ë°ì´í„° ë””ë ‰í† ë¦¬
    """
    # TODO: ìƒˆë¡œìš´ í”¼ì²˜ë¥¼ 1ê°œ ì´ìƒ ìƒì„±í•˜ì„¸ìš”!
    
    import numpy as np
    import os
    
    print("=" * 50)
    print("  Step 3: Feature Engineering")
    print("=" * 50)
    
    # ë°ì´í„° ë¡œë“œ
    X_train = np.load(f"{data_dir}/X_train.npy")
    X_test = np.load(f"{data_dir}/X_test.npy")
    
    # =======================================
    # TODO: íŒŒìƒ í”¼ì²˜ ìƒì„± ì½”ë“œ ì‘ì„±!
    # =======================================
    # 
    # í”¼ì²˜ ì¸ë±ìŠ¤ (California Housing):
    #   0: MedInc (ì¤‘ê°„ ì†Œë“)
    #   1: HouseAge (ì£¼íƒ ì—°ë ¹)
    #   2: AveRooms (í‰ê·  ë°© ìˆ˜)
    #   3: AveBedrms (í‰ê·  ì¹¨ì‹¤ ìˆ˜)
    #   4: Population (ì¸êµ¬)
    #   5: AveOccup (í‰ê·  ê±°ì£¼ì)
    #   6: Latitude (ìœ„ë„)
    #   7: Longitude (ê²½ë„)
    #
    # ì˜ˆì‹œ: ë°©ë‹¹ ì¹¨ì‹¤ ë¹„ìœ¨
    bedroom_ratio_train = X_train[:, 3] / (X_train[:, 2] + 1e-6)
    bedroom_ratio_test = X_test[:, 3] / (X_test[:, 2] + 1e-6)
    
    # TODO: ì¶”ê°€ í”¼ì²˜ë¥¼ ìƒì„±í•˜ì„¸ìš”!
    # ì˜ˆ: people_per_household = Population / AveOccup
    # ì˜ˆ: dist_to_sf = sqrt((Lat - 37.77)^2 + (Long + 122.42)^2)
    
    # í”¼ì²˜ ì¶”ê°€
    X_train_new = np.column_stack([X_train, bedroom_ratio_train])
    X_test_new = np.column_stack([X_test, bedroom_ratio_test])
    
    print(f"  âœ… Added 1 new feature(s)")
    print(f"  âœ… New shape: {X_train_new.shape}")
    
    # ì €ì¥
    output_dir = "/tmp/featured"
    os.makedirs(output_dir, exist_ok=True)
    
    np.save(f"{output_dir}/X_train.npy", X_train_new)
    np.save(f"{output_dir}/X_test.npy", X_test_new)
    
    # y ë°ì´í„° ë³µì‚¬
    import shutil
    shutil.copy(f"{data_dir}/y_train.npy", f"{output_dir}/y_train.npy")
    shutil.copy(f"{data_dir}/y_test.npy", f"{output_dir}/y_test.npy")
    
    return output_dir


# ============================================================
# TODO 4: ëª¨ë¸ í•™ìŠµ + MLflow ì»´í¬ë„ŒíŠ¸
# ============================================================

@create_component_from_func
def train_model(
    data_dir: str,
    mlflow_tracking_uri: str,
    experiment_name: str,
    n_estimators: int = 100,
    max_depth: int = 10
) -> str:
    """
    ëª¨ë¸ í•™ìŠµ ë° MLflowì— ê¸°ë¡
    
    Args:
        data_dir: í•™ìŠµ ë°ì´í„° ë””ë ‰í† ë¦¬
        mlflow_tracking_uri: MLflow ì„œë²„ URI
        experiment_name: ì‹¤í—˜ ì´ë¦„
        n_estimators: RandomForest íŠ¸ë¦¬ ê°œìˆ˜
        max_depth: RandomForest ìµœëŒ€ ê¹Šì´
    
    Returns:
        MLflow Run ID
    """
    # TODO: MLflow ì—°ë™ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”!
    
    import numpy as np
    import mlflow
    import mlflow.sklearn
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, r2_score
    import os
    
    print("=" * 50)
    print("  Step 4: Train Model")
    print("=" * 50)
    
    # MLflow ì„¤ì •
    os.environ['MLFLOW_TRACKING_URI'] = mlflow_tracking_uri
    mlflow.set_tracking_uri(mlflow_tracking_uri)
    mlflow.set_experiment(experiment_name)
    
    # ë°ì´í„° ë¡œë“œ
    X_train = np.load(f"{data_dir}/X_train.npy")
    X_test = np.load(f"{data_dir}/X_test.npy")
    y_train = np.load(f"{data_dir}/y_train.npy")
    y_test = np.load(f"{data_dir}/y_test.npy")
    
    # TODO: MLflow Run ì‹œì‘ ë° ê¸°ë¡
    with mlflow.start_run() as run:
        run_id = run.info.run_id
        
        # TODO: íŒŒë¼ë¯¸í„° ê¸°ë¡
        # íŒíŠ¸: mlflow.log_params({...})
        mlflow.log_params({
            "n_estimators": n_estimators,
            "max_depth": max_depth,
            "random_state": 42
        })
        
        # ëª¨ë¸ í•™ìŠµ
        model = RandomForestRegressor(
            n_estimators=n_estimators,
            max_depth=max_depth,
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)
        
        # í‰ê°€
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # TODO: ë©”íŠ¸ë¦­ ê¸°ë¡
        # íŒíŠ¸: mlflow.log_metrics({...})
        mlflow.log_metrics({
            "mse": mse,
            "rmse": np.sqrt(mse),
            "r2": r2
        })
        
        # TODO: ëª¨ë¸ ì €ì¥
        # íŒíŠ¸: mlflow.sklearn.log_model(...)
        mlflow.sklearn.log_model(model, "model")
        
        print(f"  âœ… R2: {r2:.4f}, RMSE: {np.sqrt(mse):.4f}")
        print(f"  âœ… Run ID: {run_id}")
    
    return run_id


# ============================================================
# (ì„ íƒ) TODO 5: KServe ë°°í¬ ì»´í¬ë„ŒíŠ¸
# ============================================================

@create_component_from_func
def deploy_model(
    run_id: str,
    model_name: str,
    namespace: str
):
    """
    KServe InferenceServiceë¡œ ëª¨ë¸ ë°°í¬
    
    Args:
        run_id: MLflow Run ID
        model_name: ë°°í¬ ëª¨ë¸ ì´ë¦„
        namespace: Kubernetes ë„¤ì„ìŠ¤í˜ì´ìŠ¤
    """
    # TODO: KServe ë°°í¬ ì½”ë“œ êµ¬í˜„ (ì„ íƒ ê³¼ì œ)
    
    print("=" * 50)
    print("  Step 5: Deploy Model (Optional)")
    print("=" * 50)
    
    # íŒíŠ¸: kubernetes ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ InferenceService ìƒì„±
    # from kubernetes import client, config
    # config.load_incluster_config()
    # api = client.CustomObjectsApi()
    # api.create_namespaced_custom_object(...)
    
    print(f"  âš ï¸  Deployment not implemented yet")
    print(f"  ğŸ’¡ Bonus: Implement KServe deployment for extra points!")


# ============================================================
# íŒŒì´í”„ë¼ì¸ ì •ì˜
# ============================================================

@dsl.pipeline(
    name='Team Project Pipeline',
    description='California Housing E2E ML Pipeline'
)
def project_pipeline(
    mlflow_tracking_uri: str = "http://mlflow-server-service.mlflow-system.svc.cluster.local:5000",
    experiment_name: str = "team-project",
    model_name: str = "california-model",
    namespace: str = "kubeflow-user01",  # TODO: ìì‹ ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ë³€ê²½!
    n_estimators: int = 100,
    max_depth: int = 10
):
    """
    Team Project Pipeline
    
    Args:
        mlflow_tracking_uri: MLflow ì„œë²„ URI
        experiment_name: MLflow ì‹¤í—˜ ì´ë¦„
        model_name: ë°°í¬ ëª¨ë¸ ì´ë¦„
        namespace: Kubernetes ë„¤ì„ìŠ¤í˜ì´ìŠ¤
        n_estimators: RandomForest íŠ¸ë¦¬ ê°œìˆ˜
        max_depth: RandomForest ìµœëŒ€ ê¹Šì´
    """
    
    # Step 1: ë°ì´í„° ë¡œë“œ
    load_task = load_data()
    
    # Step 2: ì „ì²˜ë¦¬
    preprocess_task = preprocess(data_path=load_task.output)
    
    # Step 3: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    feature_task = feature_engineering(data_dir=preprocess_task.output)
    
    # Step 4: ëª¨ë¸ í•™ìŠµ (MLflow)
    train_task = train_model(
        data_dir=feature_task.output,
        mlflow_tracking_uri=mlflow_tracking_uri,
        experiment_name=experiment_name,
        n_estimators=n_estimators,
        max_depth=max_depth
    )
    
    # Step 5: (ì„ íƒ) KServe ë°°í¬
    # deploy_model(
    #     run_id=train_task.output,
    #     model_name=model_name,
    #     namespace=namespace
    # )


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================

if __name__ == '__main__':
    print("=" * 60)
    print("  ğŸ¯ Team Project: E2E ML Pipeline")
    print("=" * 60)
    
    # íŒŒì´í”„ë¼ì¸ ì»´íŒŒì¼
    print("\n[1] Compiling Pipeline...")
    
    pipeline_file = 'project_pipeline.yaml'
    compiler.Compiler().compile(
        pipeline_func=project_pipeline,
        package_path=pipeline_file
    )
    print(f"  âœ… Compiled: {pipeline_file}")
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    print("\n[2] Submitting Pipeline...")
    
    try:
        client = kfp.Client()
        
        # TODO: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìì‹ ì˜ ê²ƒìœ¼ë¡œ ë³€ê²½!
        run = client.create_run_from_pipeline_func(
            project_pipeline,
            arguments={
                'experiment_name': 'team-XX-project',  # TODO: íŒ€ ë²ˆí˜¸ë¡œ ë³€ê²½
                'namespace': 'kubeflow-userXX',        # TODO: ìì‹ ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤
                'n_estimators': 100,
                'max_depth': 10
            },
            experiment_name='team-project-experiment',
            run_name='team-XX-run-001'  # TODO: íŒ€ ë²ˆí˜¸ë¡œ ë³€ê²½
        )
        
        print(f"  âœ… Pipeline submitted!")
        print(f"  âœ… Run ID: {run.run_id}")
        print("\nğŸ’¡ Check Kubeflow Dashboard â†’ Runs")
        
    except Exception as e:
        print(f"  âš ï¸  Could not submit: {e}")
        print(f"\nâœ… YAML created: {pipeline_file}")
        print("   Upload via Kubeflow UI")
    
    print("\n" + "=" * 60)
    print("  Good luck with your project! ğŸš€")
    print("=" * 60)
