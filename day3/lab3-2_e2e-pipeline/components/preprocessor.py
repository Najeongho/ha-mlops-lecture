"""
Lab 3-2: ë°ì´í„° ì „ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸
==============================

ë°ì´í„° ì „ì²˜ë¦¬ ë° Train/Test ë¶„í• ì„ ìˆ˜í–‰í•˜ëŠ” ì»´í¬ë„ŒíŠ¸
"""

from kfp.components import create_component_from_func


@create_component_from_func
def preprocess(
    data_path: str,
    test_size: float = 0.2,
    output_dir: str = "/tmp/processed"
) -> str:
    """
    ë°ì´í„° ì „ì²˜ë¦¬ ë° Train/Test ë¶„í• 
    
    Args:
        data_path: ì…ë ¥ ë°ì´í„° ê²½ë¡œ
        test_size: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    
    Returns:
        ì „ì²˜ë¦¬ëœ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    import json
    import os
    
    print("=" * 50)
    print("  Component: Preprocess")
    print("=" * 50)
    
    # ë°ì´í„° ë¡œë“œ
    print(f"\n  ì…ë ¥ íŒŒì¼: {data_path}")
    df = pd.read_csv(data_path)
    print(f"  ë¡œë“œëœ í–‰ ìˆ˜: {len(df)}")
    
    # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
    X = df.drop('target', axis=1)
    y = df['target']
    
    # Train/Test ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )
    
    print(f"\n  ğŸ“Š ë°ì´í„° ë¶„í• :")
    print(f"     - í•™ìŠµ ìƒ˜í”Œ: {len(X_train)}")
    print(f"     - í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(X_test)}")
    
    # ì •ê·œí™”
    print("\n  ğŸ”„ StandardScaler ì ìš© ì¤‘...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # ì €ì¥
    os.makedirs(output_dir, exist_ok=True)
    
    np.save(f"{output_dir}/X_train.npy", X_train_scaled)
    np.save(f"{output_dir}/X_test.npy", X_test_scaled)
    np.save(f"{output_dir}/y_train.npy", y_train.values)
    np.save(f"{output_dir}/y_test.npy", y_test.values)
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        "n_train": len(X_train),
        "n_test": len(X_test),
        "n_features": X_train.shape[1],
        "feature_names": list(X.columns),
        "scaler_mean": scaler.mean_.tolist(),
        "scaler_scale": scaler.scale_.tolist()
    }
    
    with open(f"{output_dir}/metadata.json", "w") as f:
        json.dump(metadata, f, indent=2)
    
    print(f"\n  âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {output_dir}")
    print(f"     - X_train.npy, X_test.npy")
    print(f"     - y_train.npy, y_test.npy")
    print(f"     - metadata.json")
    
    return output_dir


# ì»´í¬ë„ŒíŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    result = preprocess.python_func(
        data_path="/tmp/test_data.csv",
        test_size=0.2,
        output_dir="/tmp/processed"
    )
    print(f"\nê²°ê³¼: {result}")
