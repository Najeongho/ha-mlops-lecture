{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3-2: E2E ML Pipeline 통합\n",
    "\n",
    "데이터 로드부터 모델 배포까지 완전 자동화된 MLOps 파이프라인을 구축합니다.\n",
    "\n",
    "## 파이프라인 구조\n",
    "\n",
    "```\n",
    "┌─────────────┐   ┌─────────────┐   ┌─────────────┐\n",
    "│  load_data  │──▶│  preprocess │──▶│ train_model │\n",
    "└─────────────┘   └─────────────┘   └──────┬──────┘\n",
    "                                          │\n",
    "                                          ▼\n",
    "                                   ┌─────────────┐\n",
    "                                   │  evaluate   │\n",
    "                                   └──────┬──────┘\n",
    "                                          │\n",
    "                              ┌───────────┴───────────┐\n",
    "                              │                       │\n",
    "                              ▼ (deploy)              ▼ (skip)\n",
    "                       ┌─────────────┐         ┌──────────┐\n",
    "                       │   deploy    │         │  alert   │\n",
    "                       │  (KServe)   │         │          │\n",
    "                       └─────────────┘         └──────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 설치\n",
    "!pip install kfp==1.8.22 mlflow==2.9.2 scikit-learn pandas -q\n",
    "print(\"✅ 패키지 설치 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import create_component_from_func\n",
    "from kfp import compiler\n",
    "import os\n",
    "\n",
    "print(f\"KFP Version: {kfp.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수 (자신의 설정으로 변경!)\n",
    "USER_NAMESPACE = os.getenv('NAMESPACE', 'kubeflow-user01')  # 본인 네임스페이스\n",
    "\n",
    "MLFLOW_TRACKING_URI = os.getenv(\n",
    "    'MLFLOW_TRACKING_URI',\n",
    "    'http://mlflow-server-service.mlflow-system.svc.cluster.local:5000'\n",
    ")\n",
    "\n",
    "print(f\"Namespace: {USER_NAMESPACE}\")\n",
    "print(f\"MLflow URI: {MLFLOW_TRACKING_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 컴포넌트 정의\n",
    "\n",
    "### 3.1 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def load_data(data_source: str = \"sklearn\") -> str:\n",
    "    \"\"\"데이터를 로드하고 저장합니다.\"\"\"\n",
    "    import pandas as pd\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 1: Load Data\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if data_source == \"sklearn\":\n",
    "        data = fetch_california_housing()\n",
    "        df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "        df['target'] = data.target\n",
    "    else:\n",
    "        df = pd.read_csv(data_source)\n",
    "    \n",
    "    output_path = \"/tmp/raw_data.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"  ✅ Data loaded: {len(df)} rows, {len(df.columns)} columns\")\n",
    "    print(f\"  ✅ Saved to: {output_path}\")\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def preprocess(data_path: str, test_size: float = 0.2) -> str:\n",
    "    \"\"\"데이터 전처리 및 Train/Test 분할\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import os\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 2: Preprocess\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    output_dir = \"/tmp/processed\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    np.save(f\"{output_dir}/X_train.npy\", X_train_scaled)\n",
    "    np.save(f\"{output_dir}/X_test.npy\", X_test_scaled)\n",
    "    np.save(f\"{output_dir}/y_train.npy\", y_train.values)\n",
    "    np.save(f\"{output_dir}/y_test.npy\", y_test.values)\n",
    "    \n",
    "    print(f\"  ✅ Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "    print(f\"  ✅ Saved to: {output_dir}\")\n",
    "    \n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 모델 학습 (MLflow 연동)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def train_model(\n",
    "    data_dir: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    experiment_name: str = \"e2e-pipeline\",\n",
    "    n_estimators: int = 100,\n",
    "    max_depth: int = 10\n",
    ") -> str:\n",
    "    \"\"\"모델 학습 및 MLflow에 기록\"\"\"\n",
    "    import numpy as np\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    import os\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 3: Train Model\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    os.environ['MLFLOW_TRACKING_URI'] = mlflow_tracking_uri\n",
    "    \n",
    "    # 데이터 로드\n",
    "    X_train = np.load(f\"{data_dir}/X_train.npy\")\n",
    "    X_test = np.load(f\"{data_dir}/X_test.npy\")\n",
    "    y_train = np.load(f\"{data_dir}/y_train.npy\")\n",
    "    y_test = np.load(f\"{data_dir}/y_test.npy\")\n",
    "    \n",
    "    # MLflow 설정\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "        \n",
    "        # 파라미터 로깅\n",
    "        mlflow.log_params({\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"random_state\": 42\n",
    "        })\n",
    "        \n",
    "        # 모델 학습\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # 평가\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # 메트릭 로깅\n",
    "        mlflow.log_metrics({\"mse\": mse, \"rmse\": np.sqrt(mse), \"r2\": r2})\n",
    "        \n",
    "        # 모델 저장\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"  ✅ R2: {r2:.4f}, RMSE: {np.sqrt(mse):.4f}\")\n",
    "        print(f\"  ✅ Run ID: {run_id}\")\n",
    "    \n",
    "    return run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def evaluate_model(\n",
    "    run_id: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    r2_threshold: float = 0.8\n",
    ") -> str:\n",
    "    \"\"\"모델 평가 및 배포 결정\"\"\"\n",
    "    import mlflow\n",
    "    import os\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 4: Evaluate Model\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    os.environ['MLFLOW_TRACKING_URI'] = mlflow_tracking_uri\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    run = client.get_run(run_id)\n",
    "    \n",
    "    r2 = float(run.data.metrics.get(\"r2\", 0))\n",
    "    \n",
    "    print(f\"  Run ID: {run_id}\")\n",
    "    print(f\"  R2 Score: {r2:.4f}\")\n",
    "    print(f\"  Threshold: {r2_threshold}\")\n",
    "    \n",
    "    if r2 >= r2_threshold:\n",
    "        decision = \"deploy\"\n",
    "        print(f\"  ✅ Decision: DEPLOY\")\n",
    "    else:\n",
    "        decision = \"skip\"\n",
    "        print(f\"  ⚠️ Decision: SKIP\")\n",
    "    \n",
    "    return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 모델 배포 / 알림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@create_component_from_func\n",
    "def deploy_model(run_id: str, model_name: str, namespace: str, mlflow_tracking_uri: str):\n",
    "    \"\"\"KServe InferenceService로 모델 배포\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 5: Deploy Model\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"  ✅ Deploying model '{model_name}' to namespace '{namespace}'\")\n",
    "    print(f\"  ✅ Run ID: {run_id}\")\n",
    "    # 실제 배포 코드는 deployer.py 참조\n",
    "\n",
    "\n",
    "@create_component_from_func\n",
    "def send_alert(run_id: str, message: str = \"Model did not meet threshold\"):\n",
    "    \"\"\"성능 미달 알림\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 5 (Alt): Send Alert\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"  ⚠️ ALERT: {message}\")\n",
    "    print(f\"  Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 파이프라인 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='E2E ML Pipeline',\n",
    "    description='End-to-End Machine Learning Pipeline'\n",
    ")\n",
    "def e2e_ml_pipeline(\n",
    "    data_source: str = \"sklearn\",\n",
    "    mlflow_tracking_uri: str = \"http://mlflow-server-service.mlflow-system.svc.cluster.local:5000\",\n",
    "    experiment_name: str = \"e2e-pipeline\",\n",
    "    model_name: str = \"california-model\",\n",
    "    namespace: str = \"kubeflow-user01\",\n",
    "    n_estimators: int = 100,\n",
    "    max_depth: int = 10,\n",
    "    r2_threshold: float = 0.8\n",
    "):\n",
    "    # Step 1: 데이터 로드\n",
    "    load_task = load_data(data_source=data_source)\n",
    "    \n",
    "    # Step 2: 전처리\n",
    "    preprocess_task = preprocess(data_path=load_task.output)\n",
    "    \n",
    "    # Step 3: 모델 학습\n",
    "    train_task = train_model(\n",
    "        data_dir=preprocess_task.output,\n",
    "        mlflow_tracking_uri=mlflow_tracking_uri,\n",
    "        experiment_name=experiment_name,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth\n",
    "    )\n",
    "    \n",
    "    # Step 4: 평가\n",
    "    evaluate_task = evaluate_model(\n",
    "        run_id=train_task.output,\n",
    "        mlflow_tracking_uri=mlflow_tracking_uri,\n",
    "        r2_threshold=r2_threshold\n",
    "    )\n",
    "    \n",
    "    # Step 5: 조건부 배포\n",
    "    with dsl.Condition(evaluate_task.output == \"deploy\"):\n",
    "        deploy_model(\n",
    "            run_id=train_task.output,\n",
    "            model_name=model_name,\n",
    "            namespace=namespace,\n",
    "            mlflow_tracking_uri=mlflow_tracking_uri\n",
    "        )\n",
    "    \n",
    "    with dsl.Condition(evaluate_task.output == \"skip\"):\n",
    "        send_alert(run_id=train_task.output)\n",
    "\n",
    "print(\"✅ 파이프라인 정의 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 파이프라인 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_file = 'e2e_pipeline.yaml'\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=e2e_ml_pipeline,\n",
    "    package_path=pipeline_file\n",
    ")\n",
    "\n",
    "print(f\"✅ Pipeline compiled: {pipeline_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 파이프라인 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFP Client 생성\n",
    "try:\n",
    "    client = kfp.Client()\n",
    "    print(f\"✅ KFP Client connected\")\n",
    "    print(f\"   Host: {client._host}\")\n",
    "    print(f\"   Namespace: {client.get_user_namespace()}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not connect to KFP: {e}\")\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 실행\n",
    "if client:\n",
    "    run = client.create_run_from_pipeline_func(\n",
    "        e2e_ml_pipeline,\n",
    "        arguments={\n",
    "            'data_source': 'sklearn',\n",
    "            'experiment_name': 'e2e-pipeline',\n",
    "            'model_name': 'california-model',\n",
    "            'namespace': USER_NAMESPACE,\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 10,\n",
    "            'r2_threshold': 0.75\n",
    "        },\n",
    "        experiment_name='e2e-experiment',\n",
    "        run_name='e2e-run-001'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✅ Pipeline submitted!\")\n",
    "    print(f\"   Run ID: {run.run_id}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Client not connected. Upload YAML manually via Kubeflow UI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Lab 3-2 완료!\n",
    "\n",
    "### 학습한 내용\n",
    "- 다단계 파이프라인 구성\n",
    "- MLflow 통합\n",
    "- 조건부 분기 (`dsl.Condition`)\n",
    "- KServe 자동 배포\n",
    "\n",
    "### 다음 단계\n",
    "- Day 3 프로젝트 실습"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
